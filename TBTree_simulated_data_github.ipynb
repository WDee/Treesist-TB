{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import graphviz \n",
    "import sys\n",
    "import time \n",
    "import inspect\n",
    "import itertools\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import re\n",
    "\n",
    "from collections import defaultdict\n",
    "import sklearn\n",
    "from sklearn import tree\n",
    "from sklearn.tree._tree import TREE_LEAF\n",
    "from sklearn.tree import _criterion as criterions\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from matplotlib_venn import venn2, venn2_circles, venn2_unweighted\n",
    "from matplotlib_venn import venn3, venn3_circles\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyximport # pyximport.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "####UNCOMMENT THIS FOR FIRST INSTALLATION OF THE UPDATED SKLEARN MODULES\n",
    "#!python setup.py build_ext â€“inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from new_splitter import NewBestSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python sys.version_info(major=3, minor=6, micro=10, releaselevel='final', serial=0)\n",
      "pandas 1.0.1\n",
      "numpy 1.18.1\n",
      "sklearn 0.22.1\n"
     ]
    }
   ],
   "source": [
    "###show versions \n",
    "print('python', sys.version_info) #### #python sys.version_info(major=3, minor=6, micro=10, releaselevel='final', serial=0)\n",
    "print('pandas', pd.__version__)#pandas 1.0.1\n",
    "print('numpy', np.__version__)#numpy 1.18.1\n",
    "print('sklearn', sklearn.__version__)#sklearn 0.22.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "seednumber=0\n",
    "drug_list=[\"para-aminosalicylic_acid\",\"cycloserine\",\"ethionamide\",\"isoniazid\",\"rifampicin\",\"ethambutol\",\"simulation_study\"]\n",
    "drug=drug_list[-1]\n",
    "verbose=0\n",
    "n_jobs_input=5\n",
    "\n",
    "dummy_data=1\n",
    "subset_cols=1  ###adds sim to file_outputs\n",
    "number_of_cols_to_subset=100\n",
    "usecollist=list(np.arange(0,number_of_cols_to_subset,1))\n",
    "\n",
    "rule_or_or=0\n",
    "cross_validate=1\n",
    "test_size_percentage=0.2\n",
    "train_on_full_dataset=1\n",
    "use_roc_score=1\n",
    "scoring_metric=\"roc_auc\" #for cross_validation \n",
    "max_difference=1 \n",
    "max_difference_for_heatmap=1\n",
    "\n",
    "max_depth_crossval=15\n",
    "max_depth_cross_val_list=np.arange(2,max_depth_crossval+1,1)\n",
    "number_cross_val_splits=5\n",
    "fixed_max_depth=max_depth_crossval\n",
    "\n",
    "df_storage_SNP_imp=pd.DataFrame(columns=[\"SNP\",\"importance\"]) ###initalizing of empty dataframe \n",
    "\n",
    "if drug==\"simulation_study\":\n",
    "    #genomic_file2=\"rif.2021_03_16.genotyped.filtered.tmat.bin.gz\"\n",
    "    #genomic_file2=\"rif.2021_03_16.genotyped.filtered.multisplit.ann.ns.tmat.bin\"\n",
    "    prior_list=[\"GeneA\"]\n",
    "    gene_list=prior_list\n",
    "    gene_table_list=[\"GeneA\"]\n",
    "    fixed_max_depth=5\n",
    "    list_of_studies=[\"Study1\",\"Study2\",\"Study3\",\"Study4\",\"Study5\"]\n",
    "    drug_short=\"Dummy\"\n",
    "    drug_short_title=\"Dummy\"\n",
    "    drug_short_sim_title=\"Dummy_sim\"  \n",
    "    #tb_profiler_drug_calls=\"tbp_drugcalls_rifinhemb.xlsx\"\n",
    "else:\n",
    "    pass\n",
    "\n",
    "perf_dict={}\n",
    "\n",
    "if subset_cols==0:\n",
    "    drug_title=drug_short_title\n",
    "else:\n",
    "    drug_title=drug_short_sim_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "###split2\n",
    "#####functions to create new enhanced datasetes\n",
    "def imputation_with_zero_func(df):\n",
    "    df.replace({\"N\": 0},inplace=True)\n",
    "    df.replace({\"1/1\": 0},inplace=True)\n",
    "    df.replace({\"2/2\": 0},inplace=True)\n",
    "    df.replace({\"3/3\": 0},inplace=True)\n",
    "    return(df)\n",
    "\n",
    "def create_total_mutation_count_per_gene_known_cat(df,renamed_columns,append_to_df=0):\n",
    "    df.columns=renamed_columns\n",
    "    dg=df.groupby(df.columns, axis=1).sum()\n",
    "    if append_to_df==0:                     ###########DELETE LATER\n",
    "        dg.columns=dg.columns+\"_tot\"\n",
    "        out_df=dg\n",
    "    else:\n",
    "        dg.columns=dg.columns+\"_tot\"\n",
    "        out_df=pd.concat([df, dg], axis=1, join_axes=[df.index])\n",
    "    return out_df\n",
    "\n",
    "def append_counts_to_df(df,gene_known_columns,gene_unique_columns): ###not used in this version\n",
    "    df_totals=create_total_mutation_count_per_gene_known_cat(df,gene_known_columns,append_to_df=0)\n",
    "    df.columns=gene_unique_columns\n",
    "    out_df=pd.concat([df, df_totals], axis=1, join_axes=[df.index])\n",
    "    return out_df\n",
    "\n",
    "def change_index_to_column(dm,colname):  ###not used in this version\n",
    "    dm[colname] = dm.index\n",
    "    cols = list(dm)\n",
    "    cols.insert(0, cols.pop(cols.index(colname))) ###move the prevous index column to the first column\n",
    "    dm = dm.loc[:, cols]\n",
    "    dm.reset_index(drop=True, inplace=True) ###remove index column\n",
    "    dm.columns.name = None ###remove index column name\n",
    "    return(dm)\n",
    "\n",
    "class NewDecisionTreeClassifier(tree.DecisionTreeClassifier):\n",
    "    \n",
    "    def prune_tree(self):\n",
    "        for i in range(self.tree_.capacity):\n",
    "            cnt_1, cnt_0 = self.tree_.value[i][0]\n",
    "            if cnt_0 > cnt_1:\n",
    "                # this is negative node => don't split it further\n",
    "                self.tree_.children_left[i] = TREE_LEAF\n",
    "                self.tree_.children_right[i] = TREE_LEAF\n",
    "        return self.tree_\n",
    "    \n",
    "    \n",
    "    def get_max_features(self, n_features_):\n",
    "        if isinstance(self.max_features, str):\n",
    "            if self.max_features == \"auto\":\n",
    "                if is_classification:\n",
    "                    max_features = max(1, int(np.sqrt(n_features_)))\n",
    "                else:\n",
    "                    max_features = n_features_\n",
    "            elif self.max_features == \"sqrt\":\n",
    "                max_features = max(1, int(np.sqrt(n_features_)))\n",
    "            elif self.max_features == \"log2\":\n",
    "                max_features = max(1, int(np.log2(n_features_)))\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    'Invalid value for max_features. Allowed string '\n",
    "                    'values are \"auto\", \"sqrt\" or \"log2\".')\n",
    "        elif self.max_features is None:\n",
    "            max_features = n_features_\n",
    "        elif isinstance(self.max_features, (numbers.Integral, np.integer)):\n",
    "            max_features = self.max_features\n",
    "        else:  # float\n",
    "            if self.max_features > 0.0:\n",
    "                max_features = max(1,\n",
    "                                   int(self.max_features * n_features_))\n",
    "            else:\n",
    "                max_features = 0\n",
    "        return max_features\n",
    "    \n",
    "    def get_min_weight_leaf(self, sample_weight, n_samples):\n",
    "        if sample_weight is None:\n",
    "            min_weight_leaf = (self.min_weight_fraction_leaf *\n",
    "                               n_samples)\n",
    "        else:\n",
    "            min_weight_leaf = (self.min_weight_fraction_leaf *\n",
    "                               np.sum(sample_weight)) \n",
    "        return min_weight_leaf\n",
    "    \n",
    "    def fit(self, X, y, sample_weight=None, check_input=True,\n",
    "            X_idx_sorted=None, prune_tree=True):\n",
    "        if self.splitter == 'new_best':\n",
    "            n_samples, n_features_ = X.shape\n",
    "            crit = criterions.Gini(1, np.array([2]))\n",
    "            self.splitter = NewBestSplitter(crit, #crit,\n",
    "                                   self.get_max_features(n_features_),\n",
    "                                   self.min_samples_leaf,\n",
    "                                   self.get_min_weight_leaf(sample_weight, n_samples),\n",
    "                                   check_random_state(self.random_state)\n",
    "                                  )\n",
    "        super(NewDecisionTreeClassifier, self).fit(\n",
    "            X, y,\n",
    "            sample_weight=sample_weight,\n",
    "            check_input=check_input,\n",
    "            X_idx_sorted=X_idx_sorted)\n",
    "        \n",
    "        if prune_tree:\n",
    "            self.prune_tree()\n",
    "        return self\n",
    "    \n",
    "    def get_stats(self, feature_names=None):\n",
    "        def _name(idx):\n",
    "            if feature_names is None:\n",
    "                return idx\n",
    "            else:\n",
    "                return feature_names[idx\n",
    "                                    ]\n",
    "        if isinstance(self.splitter, NewBestSplitter):\n",
    "            result = []\n",
    "            ties = self.splitter.get_current_node_ties()\n",
    "            for i in range(self.splitter.get_node_idx() + 1):\n",
    "                result.append([_name(idx) for idx in np.flatnonzero(ties[i])])\n",
    "            return result\n",
    "        else:\n",
    "            raise ValueError('this action is supported for NewBestSplitter only')\n",
    "\n",
    "(LEAF_SENSITIVE, LEAF_RESISTANT, \n",
    " NODE_REGULAR, \n",
    " NODE_AND_UPPER, NODE_AND_LOWER, \n",
    " NODE_REVERSE_UPPER, NODE_REVERSE_LOWER) = ['_leaf_sens_', '_leaf_res_', \n",
    "                                           '_reg_', \n",
    "                                           '_and_up_', '_and_low_',\n",
    "                                           '_rev_up_', '_rev_low']\n",
    "           \n",
    "\n",
    "\n",
    "def is_left_child(tree):\n",
    "    \"\"\"\n",
    "    True - node is left child (i.e. it's close to \"zero\" class)\n",
    "    False - node is right child (i.e. it's close to \"one\" class)\n",
    "    \"\"\"\n",
    "    return ([True] # root of the tree is assumed to be left child\n",
    "            + [node_idx in tree.children_left\n",
    "               for node_idx in range(1, tree.capacity)]\n",
    "           )\n",
    "           \n",
    "def get_feature_types(feature_names, stats, is_left_nodes):\n",
    "    result = {f: FeatureType.NotUsed for f in feature_names}\n",
    "    all_ties = []\n",
    "    \n",
    "    def _pure_tie(tie):\n",
    "        for feature in tie:\n",
    "            if result[feature] != FeatureType.AndTie:\n",
    "                result[feature] = FeatureType.PureTie\n",
    "                \n",
    "    def _regular(feature):\n",
    "        result[feature] = FeatureType.Regular\n",
    "        \n",
    "    def _and_tie(feature):\n",
    "        was_in_tie = False\n",
    "        for tie in all_ties:\n",
    "            if feature in tie:\n",
    "                was_in_tie = True\n",
    "                for anoth_feature in tie:\n",
    "                    result[anoth_feature] = FeatureType.AndTie\n",
    "        if not was_in_tie:\n",
    "            _regular(feature)\n",
    "    \n",
    "    for node_ties, is_left in zip(stats, is_left_nodes):\n",
    "        if len(node_ties) > 1:\n",
    "            all_ties.append(node_ties)\n",
    "            _pure_tie(node_ties)\n",
    "        elif len(node_ties) == 1:\n",
    "            feature = node_ties[0]\n",
    "            if is_left:\n",
    "                _regular(feature)\n",
    "            else:\n",
    "                # node turned right\n",
    "                _and_tie(feature)\n",
    "    return result\n",
    "           \n",
    "def filter_stats(stats, feature_types, desired_feature_type):\n",
    "    return [[feature for feature in node_stats\n",
    "             if feature_types[feature] == desired_feature_type] \n",
    "            for node_stats in stats]\n",
    "\n",
    "from enum import Enum\n",
    "class FeatureType(Enum):\n",
    "    NotUsed = 0\n",
    "    Regular = 1\n",
    "    PureTie = 2\n",
    "    AndTie = 3\n",
    "    \n",
    "def get_feature_importance_from_random_forest(X,y,df_x,save_file=1): ###not used in this version\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    rnd_clf = RandomForestClassifier(n_estimators=100, max_features=None,n_jobs=n_jobs_input, random_state=None)\n",
    "    rnd_clf.fit(X, y)\n",
    "    df_out=pd.DataFrame(zip(df_x.columns, rnd_clf.feature_importances_))\n",
    "    df_out.columns=[\"SNP\",\"importance\"]\n",
    "    df_out[\"SNP\"]=df_out[\"SNP\"].str.split(\"_\",expand=True)\n",
    "    if verbose==1:\n",
    "        print(df_out.shape,\"shape before\")\n",
    "    df_out=df_out[df_out[\"importance\"]>0]  ###importance greater than 0\n",
    "    if verbose==1:\n",
    "        print(df_out.shape,\"shape after\")\n",
    "    dg=df_out.groupby(\"SNP\").count()\n",
    "    if verbose==1:\n",
    "        print(dg.shape,\"shape before\")\n",
    "    dg=dg[dg[\"importance\"]>1] #####used more than 1 \n",
    "    if verbose==1:\n",
    "        print(dg.shape,\"shape after\")\n",
    "    dz=dg.sort_values(\"importance\",ascending=False)\n",
    "    if save_file==1:\n",
    "        dz.to_csv(title)\n",
    "    return(dz)\n",
    "\n",
    "def show_allele_freq_table(df):\n",
    "    y=np.bincount(np.sum(df.values,axis=1))\n",
    "    ii = np.nonzero(y)[0]\n",
    "    print(np.vstack((ii,y[ii])).T)\n",
    "\n",
    "def create_bargraph_from_store_dict(store_dict,save=0):\n",
    "    keys = ['_'.join(i) for i in store_dict.keys()]\n",
    "    keys, values = zip(*sorted(zip(keys, store_dict.values())))\n",
    "    if save==1:\n",
    "        plt.savefig(\"barchart_stepdown.png\")\n",
    "    plt.bar(keys, values)\n",
    "\n",
    "def get_sort_order_to_have_prior_columns_first(prior_list,df):\n",
    "    store_array=np.zeros(df.shape[1])\n",
    "    prior_list=[\"unique_id\"]+prior_list\n",
    "    i=-50\n",
    "    for gene in prior_list:\n",
    "        store_array=store_array+df.columns.str.contains(gene)*i\n",
    "        i=i+1\n",
    "    if verbose==1:\n",
    "        print(store_array)\n",
    "    return(store_array)    \n",
    "\n",
    "def generate_new_combinations_stepping_down(list_values):\n",
    "    return(list(itertools.combinations(list_values,len(list_values)-1)))\n",
    "\n",
    "def scoring_function(test):\n",
    "    return(np.sum([dict_values[x] for x in test]))\n",
    "\n",
    "def generate_new_combinations_stepping_up(combinations,list_values):\n",
    "    return([list(combinations[0])+list(x) for x in list_values if x not in list(combinations[0])])\n",
    "\n",
    "def score_all_entries(combinations,scoring_function):\n",
    "    return(zip(combinations,map(scoring_function,combinations))) ###change \n",
    "\n",
    "def get_highest_entry_index(scored_list):\n",
    "    return(np.argmax([x[1] for x in scored_list]))\n",
    "\n",
    "def get_key_with_max_value(values_dict):\n",
    "    return(max(values_dict, key=values_dict.get))\n",
    "  \n",
    "def create_dict_score_by_size_studygroup(scores_across_all_combinations_dict):\n",
    "    score_lists_for_combi_number = defaultdict(list)\n",
    "    for i in list(set([len(x) for x in scores_across_all_combinations_dict.keys()])):\n",
    "        [score_lists_for_combi_number[len(x)].append(scores_across_all_combinations_dict[x]) for x in scores_across_all_combinations_dict.keys() if len(x)==i]\n",
    "    return(score_lists_for_combi_number)\n",
    "\n",
    "def get_sort_order_to_have_prior_columns_first(prior_list,df):\n",
    "    store_array=np.zeros(df.shape[1])\n",
    "    prior_list=[\"unique_id\"]+prior_list\n",
    "    i=-50\n",
    "    for gene in prior_list:\n",
    "        store_array=store_array+df.columns.str.contains(gene)*i\n",
    "        i=i+1\n",
    "    if verbose==1:\n",
    "        print(store_array)\n",
    "    return(store_array)  \n",
    "\n",
    "def resort_dataframe_based_on_priors(prior_list,df_x):\n",
    "    sort_order=get_sort_order_to_have_prior_columns_first(prior_list,df_x)    \n",
    "    new_column_order=[x for _,x in sorted(zip(sort_order,df_x.columns),reverse=False)]\n",
    "    df_x=df_x[new_column_order]\n",
    "    X=df_x.values  \n",
    "    return(df_x, X)\n",
    "\n",
    "def run_cross_validation(model,param_grid,number_cross_val_splits,scoring_metric,verbose=1):\n",
    "    kfold = StratifiedKFold(n_splits=number_cross_val_splits, shuffle=True, random_state=seednumber)\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring=scoring_metric, cv=kfold, verbose=1,refit=\"accuracy\",n_jobs=n_jobs_input)#,refit=False) n_jobs=-1,\n",
    "    grid_result = grid_search.fit(X, y)\n",
    "    results=grid_result.cv_results_\n",
    "    if verbose==1:\n",
    "        print(grid_result.best_params_) \n",
    "        print({k: v for k, v in results.items() if k.startswith(('mean_test','std_test'))})\n",
    "    return(grid_result)\n",
    "\n",
    "def split_dataset_train_test(X, y, test_size_percentage,verbose,seednumber):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seednumber, test_size=test_size_percentage,stratify=y) ###stratify on y\n",
    "    if verbose==1:\n",
    "        print(np.sum(y_test),\"number of values in y_test\")\n",
    "        print(np.sum(y),\"number of values in entire dataset\")\n",
    "    return(X_train, X_test, y_train, y_test)\n",
    "\n",
    "def get_node_types(clf):\n",
    "    def is_leaf(i):\n",
    "        return ((clf.tree_.children_left[i] == TREE_LEAF)\n",
    "                and (clf.tree_.children_right[i] == TREE_LEAF))\n",
    "    def is_sens(i):\n",
    "        cnt_1, cnt_0 = clf.tree_.value[i][0]\n",
    "        return cnt_0 <= cnt_1\n",
    "    def is_res(i):\n",
    "        cnt_1, cnt_0 = clf.tree_.value[i][0]\n",
    "        return cnt_0 > cnt_1\n",
    "    \n",
    "    def is_and(i):\n",
    "        r_child = clf.tree_.children_right[i]\n",
    "        if is_leaf(r_child):\n",
    "            return False\n",
    "        r_grandchild = clf.tree_.children_right[r_child]\n",
    "        if is_leaf(r_grandchild) and is_res(r_grandchild):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def is_revers(i):\n",
    "        r_child = clf.tree_.children_right[i]\n",
    "        if is_leaf(r_child):\n",
    "            return False\n",
    "        r_grandchild = clf.tree_.children_right[r_child]\n",
    "        if is_leaf(r_grandchild) and is_sens(r_grandchild):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    result = {}\n",
    "    for i in range(clf.tree_.capacity):\n",
    "        if i in result:\n",
    "            continue\n",
    "        if is_leaf(i):\n",
    "            # it's leaf\n",
    "            result[i] = LEAF_RESISTANT if is_res(i) else LEAF_SENSITIVE\n",
    "        else:\n",
    "            # it's node\n",
    "            result[i] = NODE_REGULAR\n",
    "            if is_and(i):\n",
    "                result[i] = NODE_AND_UPPER\n",
    "                result[clf.tree_.children_right[i]] = NODE_AND_LOWER\n",
    "            if is_revers(i):\n",
    "                result[i] = NODE_REVERSE_UPPER\n",
    "                result[clf.tree_.children_right[i]] = NODE_REVERSE_LOWER\n",
    "            \n",
    "    return result\n",
    "\n",
    "def add_node_type_to_dot_data(node2type_dict, dot_data):\n",
    "    res = dot_data[:]\n",
    "    for node_id, node_type in node2type_dict.items():\n",
    "        res = res.replace(f'\\n{node_id} [label=<',\n",
    "                                    f'\\n{node_id} [label=<{node_type}<br/>')\n",
    "    return res\n",
    "\n",
    "###Plotting funcgtions \n",
    "def plot_tree_per_study(clf, feature_names, show_node_types=True, show_id=False,study=\"tbd\",title_graph=\"undefined\"):\n",
    "    dot_data = tree.export_graphviz(clf, \n",
    "                                feature_names=feature_names,\n",
    "                                    class_names=[\"sensitive\", \"resistant\"],\n",
    "                                    node_ids=show_id,\n",
    "                                out_file=None,\n",
    "                                filled=True, \n",
    "                                rounded=True, \n",
    "                                special_characters=True) \n",
    "    if show_node_types:\n",
    "        if 'node2type' in dir(clf):\n",
    "            node2type_dict = clf.node2type\n",
    "        else:\n",
    "            node2type_dict = get_node_types(clf)\n",
    "        dot_data = add_node_type_to_dot_data(node2type_dict, dot_data)\n",
    "    graph = graphviz.Source(dot_data)  \n",
    "    graph.render(title_graph);\n",
    "    return graphviz.Source(dot_data)\n",
    "\n",
    "def plot_tree(clf, feature_names, show_node_types=True, show_id=False,title_graph=\"undefined\"):\n",
    "    dot_data = tree.export_graphviz(clf, \n",
    "                                feature_names=feature_names,\n",
    "                                    class_names=[\"sensitive\", \"resistant\"],\n",
    "                                    node_ids=show_id,\n",
    "                                out_file=None,\n",
    "                                filled=True, \n",
    "                                rounded=True, \n",
    "                                special_characters=True) \n",
    "    if show_node_types:\n",
    "        if 'node2type' in dir(clf):\n",
    "            node2type_dict = clf.node2type\n",
    "        else:\n",
    "            node2type_dict = get_node_types(clf)\n",
    "        dot_data = add_node_type_to_dot_data(node2type_dict, dot_data)\n",
    "        \n",
    "    graph = graphviz.Source(dot_data)  \n",
    "    graph.render(title_graph);\n",
    "    return graphviz.Source(dot_data)\n",
    "\n",
    "def plot_tree_backwards_stepping(clf,columns_of_df,study,title_graph=\"undefined\"):\n",
    "    dot_data = tree.export_graphviz(clf, out_file=None, class_names=[\"sensitive\", \"resistant\"], feature_names=columns_of_df,filled=True, rounded=True, special_characters=True)  \n",
    "    graph = graphviz.Source(dot_data)  \n",
    "    graph.render(title_graph);\n",
    "    return(graph) \n",
    "\n",
    "def split_string_authoryearcountry(string):\n",
    "    dict_trans={\"pe\":\"Peru\",\"kr\":\"Korea\",\"cn\":\"China\",\"pt\":\"Portugal\",\"ru\":\"Russia\",\"uz\":\"Uzbekistan\",\"za\":\"Zambia\",\"by\":\"Belarus\",\"tn\":\"Tunisia\",\"pk\":\"Pakistan\",\"mw\":\"Malawi\",\"NA\":\"NA\",\"th\":\"Thailand\",\"ph\":\"Philipines\",\"gb\":\"Great_Britain\"}\n",
    "    string_authoryear=string.split(\"_\")[0]\n",
    "    match = re.match(r\"([a-z]+)([0-9]+)\", string_authoryear, re.I)\n",
    "    if match:\n",
    "        items = match.groups()\n",
    "        string_author=items[0].capitalize()\n",
    "        string_year=items[1]\n",
    "        string_country_short=string.split(\"_\")[1]\n",
    "        string_country_long=dict_trans[string_country_short]\n",
    "        return(string_author+\" (\"+string_year+\", \"+string_country_long+\")\")\n",
    "\n",
    "def plot_scatter_points_by_size_studygroup(scores_across_all_combinations_dict,score_lists_for_combi_number,title_graph):\n",
    "    store_max=[]\n",
    "    x_coords=[]\n",
    "    x = np.array(list(set([len(x) for x in scores_across_all_combinations_dict.keys()])))\n",
    "    for i in list(set([len(x) for x in scores_across_all_combinations_dict.keys()])):\n",
    "        x_array=np.repeat(i,len(score_lists_for_combi_number[i]))\n",
    "        plt.plot(x_array, score_lists_for_combi_number[i], '.')\n",
    "        store_max.append(max(score_lists_for_combi_number[i]))\n",
    "        x_coords.append(i)\n",
    "    plt.plot(np.array(x_coords), np.array(store_max), '-',color=\"grey\")\n",
    "    for value,xy in enumerate(zip(np.array(x_coords)+0.05, np.array(store_max)+0.5)):                                       # <--\n",
    "        plt.annotate('%s' % store_max[value], xy=xy, textcoords='data')\n",
    "    plt.xlabel(\"Size of subset\")\n",
    "    plt.ylabel(\"Performance\")\n",
    "    plt.savefig(title_graph)\n",
    "    plt.show()\n",
    "\n",
    "def plot_crossval(max_depth,scores,title_graph,yerr):\n",
    "    plt.plot(max_depth, scores)\n",
    "    plt.legend()\n",
    "    plt.xlabel('max_depth')\n",
    "    plt.ylabel('accuracy')\n",
    "    title=title_graph\n",
    "    plt.title(title)\n",
    "    axes = plt.gca()\n",
    "    lowerb=np.round(np.min(scores)*0.8,1)\n",
    "    axes.set_ylim([lowerb,1])\n",
    "    plt.errorbar(max_depth, scores, yerr=yerr)\n",
    "    plt.savefig(title)\n",
    "\n",
    "def plot_and_build_heatmap(drug_title,inputfile,remove_importance_label=1,sort_on_snp_loc=1,titlesave=None,subset_list=None):\n",
    "    df=pd.read_csv(inputfile).iloc[:,:]\n",
    "    df.drop(\"feature_genes\",axis=1,inplace=True)\n",
    "    df.index=[x.rsplit('_', 1)[0]+\" (\"+x.rsplit('_', 1)[1]+\")\" for x in df[\"SNP\"]]\n",
    "    ###resort\n",
    "    if sort_on_snp_loc==1:\n",
    "        df[\"sort\"]=[x.rsplit('_', 1)[1] for x in df[\"SNP\"]]\n",
    "        df[\"sort\"]=df[\"sort\"].astype(float)\n",
    "        df.sort_values('sort',inplace=True,ascending=True)\n",
    "        df.drop(columns=[\"sort\"], inplace=True)\n",
    "    ###arrange columns    \n",
    "    if remove_importance_label==1:\n",
    "        df.columns=[x[11:] for x in df.columns]\n",
    "    try:\n",
    "        new_cols=[split_string_authoryearcountry(x) for x in df.columns]\n",
    "    except:\n",
    "        new_cols=df.columns\n",
    "\n",
    "    df=df.iloc[:,3:]\n",
    "    df.columns=new_cols[3:]\n",
    "    print(new_cols[3:],\"columns check\")\n",
    "    \n",
    "    for i in subset_list:\n",
    "        df[df.index.str.contains(i)]=df[df.index.str.contains(i)]+40\n",
    "    \n",
    "    if drug_title==\"ETN\":\n",
    "        fig, ax = plt.subplots(figsize=(10, 20))\n",
    "    else:\n",
    "        fig, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "    sb.heatmap(df, cmap=\"Greens\", linewidth=0.3, cbar_kws={\"shrink\": .8},xticklabels=True, yticklabels=True,cbar=False)\n",
    "\n",
    "    # title\n",
    "    title = 'Feature Inclusion\\n'.upper()\n",
    "    plt.title(title, loc='left')\n",
    "    plt.savefig(titlesave)\n",
    "    plt.show()\n",
    "\n",
    "weights = {0:1.0, 1:1.0}\n",
    "\n",
    "class ShortListDecisionTreeClassifier(NewDecisionTreeClassifier):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.feature_genes = kwargs.pop('feature_genes')\n",
    "        self.short_list = kwargs.pop('short_list')\n",
    "        self.max_difference = kwargs.pop('max_difference')\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def prune_tree_short_list(self):\n",
    "        tree_ = self.tree_\n",
    "        short_list = set(self.short_list)\n",
    "        updated_list = short_list.copy()\n",
    "        self.node2type = get_node_types(self)\n",
    "        \n",
    "        visited = set()\n",
    "        queue = []  # queue\n",
    "\n",
    "        def can_add_gene(current_gene):\n",
    "            difference = (updated_list.union([current_gene])) - short_list\n",
    "            return len(difference) <= self.max_difference\n",
    "        \n",
    "        def make_leaf(i):\n",
    "            tree_.children_left[i] = TREE_LEAF\n",
    "            tree_.children_right[i] = TREE_LEAF\n",
    "            \n",
    "        def enqueue_children(i):\n",
    "            for next_node in [tree_.children_left[i],  # go to left child first\n",
    "                              tree_.children_right[i]  # go to right child then\n",
    "                             ]:\n",
    "                if not next_node in visited:\n",
    "                    queue.append(next_node)\n",
    "        \n",
    "        def process_node(i):\n",
    "            if i in visited:  \n",
    "                return\n",
    "            visited.add(i) \n",
    "        \n",
    "            node_type = self.node2type[i]\n",
    "            if node_type in [LEAF_RESISTANT, LEAF_SENSITIVE]:\n",
    "                return\n",
    "            cnt_1, cnt_0 = tree_.value[i][0]\n",
    "            if cnt_0 > cnt_1:\n",
    "                # this is negative node => don't split it further\n",
    "                make_leaf(i)\n",
    "                return\n",
    "            else:\n",
    "                current_feature = tree_.feature[i]\n",
    "                current_gene = self.feature_genes[current_feature]\n",
    "                can_add = can_add_gene(current_gene)\n",
    "    #             print(f'{features_names[current_feature]} updated_list = {updated_list} can_add = {can_add}')\n",
    "                if not can_add:\n",
    "                    if node_type == NODE_AND_LOWER:  # dont prune and_low nodes\n",
    "                        # we do no count and_low's gene as a new added gene\n",
    "                        enqueue_children(i) \n",
    "                    else:\n",
    "                        make_leaf(i)\n",
    "                        return\n",
    "                else:\n",
    "                    if node_type == NODE_AND_LOWER:\n",
    "                        # we do no count and_low's gene as a new added gene\n",
    "                        enqueue_children(i)\n",
    "                    else:\n",
    "                        updated_list.update([current_gene]) # take this gene into account\n",
    "                        enqueue_children(i)\n",
    "            \n",
    "            while queue:\n",
    "                process_node(queue.pop(0))\n",
    "        \n",
    "        process_node(0)  # start with top node          \n",
    "        return tree_\n",
    "    \n",
    "    def fit(self, X, y, sample_weight=None, check_input=True,\n",
    "            X_idx_sorted=None):\n",
    "        super().fit(\n",
    "            X, y,\n",
    "            sample_weight=sample_weight,\n",
    "            check_input=check_input,\n",
    "            X_idx_sorted=X_idx_sorted,\n",
    "            prune_tree=False)\n",
    "        \n",
    "        self.prune_tree_short_list()\n",
    "        return self\n",
    "\n",
    "def feature_mapper(feature_name):\n",
    "    return feature_name.rsplit('_',1)[0]\n",
    "\n",
    "def print_html_cv_table(title_graph,results):\n",
    "    pd.DataFrame({k: v for k, v in results.items() if k.startswith(('mean_test','std_test'))}).to_html(title_graph)\n",
    "\n",
    "def summarize_crossval_accuracy(grid_result):\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    print(means,\"means\")\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    scores = np.array(means)#.reshape(len(max_depth))\n",
    "    return scores\n",
    "\n",
    "def get_prior_list_and_max_diff(string,shortlist,max_difference):\n",
    "    boolean_list=[x in shortlist for x in string]\n",
    "    out2=[i for i, n in enumerate(boolean_list) if n == True]+[i for i, n in enumerate(boolean_list) if n == False][:max_difference]\n",
    "    return(out2,np.array(string)[out2])\n",
    "\n",
    "def get_metrics_predictions(cm):\n",
    "    TP = cm[1][1]\n",
    "    FP = cm[0][1]\n",
    "    FN = cm[1][0]\n",
    "    TN = cm[0][0]\n",
    "\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = np.true_divide(TP,(TP+FN))\n",
    "    # Specificity or true negative rate\n",
    "    TNR = np.true_divide(TN,(TN+FP))\n",
    "    # Precision or positive predictive value\n",
    "    PPV = np.true_divide(TP,(TP+FP))\n",
    "    # Negative predictive value\n",
    "    NPV = np.true_divide(TN,(TN+FN))\n",
    "    # Fall out or false positive rate\n",
    "    FPR = np.true_divide(FP,(FP+TN))\n",
    "    # False negative rate\n",
    "    FNR = np.true_divide(FN,(TP+FN))\n",
    "    # False discovery rate\n",
    "    FDR = np.true_divide(FP,(TP+FP))\n",
    "    ACC = np.true_divide(TP+TN,TP+FP+FN+TN)\n",
    "    return(TPR,TNR,PPV,NPV,FPR,FNR,FDR,ACC)\n",
    "\n",
    "def subset_study(dm,study_grouping,drug):\n",
    "    dm_per_study=dm[dm[\"study_country_concat\"].isin(study_grouping)] ###subset for given study \n",
    "    y=dm_per_study[drug]  ###select y_labels\n",
    "    dm_per_study.drop([drug,\"study_country_concat\"],inplace=True,axis=1) ###remove drug and study column\n",
    "    columns_of_df=dm_per_study.columns\n",
    "    X=dm_per_study.values ###select X values \n",
    "    return y,X,columns_of_df\n",
    "\n",
    "def get_feature_importance_from_tree(clf,columns_of_df,study,df_storage_SNP_imp,verbose=0,max_difference=3):\n",
    "    dg=pd.DataFrame(zip([columns_of_df[x] for x in clf.tree_.feature],clf.tree_.feature,[clf.feature_importances_[x] for x in clf.tree_.feature]))\n",
    "    importance_column=\"importance\"+\"_\"+str(study)\n",
    "    #importance_column=str(study)\n",
    "    dg.columns=[\"SNP\",\"feature\",importance_column];dg=dg[[\"SNP\",importance_column]];dg.sort_values([importance_column],ascending=True)\n",
    "    if verbose==1:\n",
    "        print(dg)\n",
    "    dg=dg[dg[importance_column]>0]\n",
    "    dg[\"feature_genes\"]=[feature_mapper(f) for f in dg.SNP] ####get genes\n",
    "    indexbool,shortlist_genes=get_prior_list_and_max_diff(dg[\"feature_genes\"],prior_list,max_difference) ###subset only prior_list and max_difference genes\n",
    "    print(indexbool,\"indexbool\")\n",
    "    dg=dg.iloc[indexbool] ###save\n",
    "    df_storage_SNP_imp=pd.merge(df_storage_SNP_imp,dg,on=\"SNP\",how=\"outer\")\n",
    "    df_storage_SNP_imp.drop(\"feature_genes\",axis=1,inplace=True)\n",
    "    return(df_storage_SNP_imp)\n",
    "\n",
    "def extract_gene_from_columnname(dm):\n",
    "    features_names = list(dm.columns[0: dm.shape[1]]) \n",
    "    features_names.remove(drug)\n",
    "    features_names.remove('study_country_concat')\n",
    "    feature_genes = [feature_mapper(f) for f in features_names]\n",
    "    return features_names,feature_genes\n",
    "\n",
    "def lookup_grade_bef(score):\n",
    "    #print(type(score),\"score type\")\n",
    "    #print(score,\"score\")\n",
    "    score=int(score)\n",
    "    match = (df_gff['Start'] <= score) & (df_gff['End'] > score)\n",
    "    #print(match,\"match\")\n",
    "    grade = df_gff['Gene'][match]\n",
    "    if np.sum(grade.values)==0:\n",
    "        match = df_gff['End'] > score\n",
    "        if(np.sum(match))==0:\n",
    "            grade=pd.Series([score])\n",
    "        else:\n",
    "            grade = df_gff['Gene'][match]+\"_bef\"\n",
    "    return grade.values[0]\n",
    "\n",
    "#####functions to create new enhanced datasetes\n",
    "def col_from_snp_to_gene_simple(snp_series):\n",
    "    genes_series=list(map(str, pd.Series(snp_series).apply(lookup_grade_bef).tolist())) ###using the bef adjustment\n",
    "    return(genes_series)\n",
    "\n",
    "def create_pos_and_gene_df(df_x, number_of_columns_to_remove_at_end):\n",
    "    df_pos_info=pd.DataFrame(df_x.columns[:-number_of_columns_to_remove_at_end].astype(float));df_pos_info.columns=[\"positions\"]\n",
    "    df_pos_info[\"gene\"]=0;df_pos_info[\"snp_counter\"]=0;df_pos_info[\"unique_id\"]=0; df_pos_info[\"gene_known\"]=0\n",
    "    df_pos_info[\"gene\"]=col_from_snp_to_gene_simple(df_pos_info[\"positions\"])\n",
    "    df_pos_info[\"positions\"]=df_pos_info[\"positions\"].astype(str)\n",
    "    df_pos_info[\"unique_id\"]=df_pos_info[\"gene\"]+\"_\"+df_pos_info[\"positions\"] \n",
    "    genes_and_pos_columns=list(df_pos_info[\"unique_id\"])\n",
    "    columns_to_add_to_end=list(df_x.columns[-2:])\n",
    "    if verbose==1:\n",
    "        print(columns_to_add_to_end,\"columns_to_add_to_end\")\n",
    "    renamed_columns=genes_and_pos_columns+columns_to_add_to_end\n",
    "    return renamed_columns,df_pos_info\n",
    "\n",
    "def prepare_dataset(df_dst,df_genomic,study_grouping):\n",
    "    df_genomic2=df_genomic.copy()\n",
    "    df_dst_subset=df_dst[df_dst[\"study_country_concat\"].isin(study_grouping)] ###subset df_subset\n",
    "    df_genomic2.set_index('run_accession', inplace=True)\n",
    "    df_dst_subset.set_index('wgs_id', inplace=True)\n",
    "    ###merge to align dst file with genomic file\n",
    "    df_merge=pd.merge(df_genomic2,df_dst_subset,left_index=True,right_index=True,how=\"left\") ###merge the genomic database and the study file on accession number ###index based merging saves a lot of time\n",
    "    df_merge.dropna(subset=[drug],inplace=True) ###drop NA values\n",
    "    #####sort the dataframe based on prior list \n",
    "    renamed_columns,df_merge_pos_info=create_pos_and_gene_df(df_merge,2); df_merge.columns=renamed_columns\n",
    "    sort_order=get_sort_order_to_have_prior_columns_first(prior_list,df_merge)    \n",
    "    new_column_order=[x for _,x in sorted(zip(sort_order,df_merge.columns),reverse=False)]\n",
    "    df_merge=df_merge[new_column_order]\n",
    "    return(df_merge)\n",
    "\n",
    "def accuracy_and_cm(X_test,y_test,selection_model):\n",
    "    y_pred = selection_model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print()\n",
    "    print(cm); print()\n",
    "    TPR,TNR,PPV,NPV,FPR,FNR,FDR,ACC = accuracy_metrics(cm)\n",
    "    print(\"TPR = %0.2f, TNR = %0.2f, ACC = %0.2f\" % (TPR*100,TNR*100,ACC*100))\n",
    "    return(ACC,TPR,TNR,y_pred,PPV,NPV)  \n",
    "\n",
    "def fit_model(clf,X_input,y_input,show_accuracy=1):\n",
    "    clf = clf.fit(X, y)\n",
    "    if show_accuracy==1:\n",
    "        accuracy_score=clf.score(X, y, sample_weight=None)\n",
    "    print(accuracy_score,\"accuracy score on training data\")\n",
    "    return(clf)\n",
    "\n",
    "def make_predictions(clf,X_to_test,y_to_compare):\n",
    "    predictions_prob = clf.predict_proba(X_to_test)\n",
    "    predictions_binary = clf.predict(X_to_test)\n",
    "    cm=confusion_matrix(y, predictions_binary)\n",
    "    return(predictions_prob,predictions_binary,cm)\n",
    "\n",
    "def get_roc_score(y, predictions):\n",
    "    try:\n",
    "        print(roc_auc_score(y, predictions[:,1]),\"roc auc score\")\n",
    "        roc_score=roc_auc_score(y, predictions[:,1])\n",
    "    except:\n",
    "        print(\"failure_to_calculate_ROC\")\n",
    "        roc_score=0\n",
    "    return(roc_score)\n",
    "\n",
    "def cross_validation_regular_tree(number_cross_val_splits,plotting,verbose,scoring_metric,max_depth_cross_val_list):\n",
    "    param_grid = dict(max_depth=max_depth_cross_val_list)\n",
    "    model = tree.DecisionTreeClassifier(criterion=\"gini\",min_samples_leaf=2,random_state=seednumber) ###remove jobs=-1\n",
    "    grid_result=run_cross_validation(model,param_grid,number_cross_val_splits,scoring_metric,verbose=1)\n",
    "    max_depth_setting=grid_result.best_params_[\"max_depth\"] ###re-use the cross_valudated optimal value\n",
    "\n",
    "    if verbose==1:\n",
    "        print(max_depth_setting)\n",
    "        print(grid_result.best_params_)\n",
    "\n",
    "    scores=summarize_crossval_accuracy(grid_result)\n",
    "\n",
    "    ###plotting\n",
    "    title_graph=drug_title+\"_crossval_regtree\"+\"_cv\"\n",
    "    plot_crossval(max_depth_cross_val_list,scores,title_graph,grid_result.cv_results_['std_test_score'])\n",
    "    return(max_depth_setting)\n",
    "    \n",
    "\n",
    "def add_str_cols(df, prefix='abc', num_cols=2):\n",
    "    new_cols = [f'{prefix}.{n}' for n in range(num_cols)]\n",
    "    values = np.random.choice([0, 1], size=[len(df), num_cols])\n",
    "    df[new_cols] = values\n",
    "    return df\n",
    "\n",
    "def get_column_groups(columns):\n",
    "    res = {}\n",
    "    for col in columns:\n",
    "        if '.' in str(col):\n",
    "            parts = str(col).split('.')\n",
    "            assert len(parts) == 2, f\"wrong column name (too many dots): {col}\"\n",
    "            first, last = parts\n",
    "            if first in res:\n",
    "                res[first] = res[first] + [col]\n",
    "            else:\n",
    "                res[first] = [col]\n",
    "    return res\n",
    "\n",
    "def aggregate_groups(df, column_groups, new_col_suffix='.9'):\n",
    "    for group, cols in column_groups.items():\n",
    "        df[f'{group}{new_col_suffix}'] = df[cols].any(axis=1).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dummy_data==1:\n",
    "    df=pd.read_csv(\"wgs_dummydata_v3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_accession</th>\n",
       "      <th>1</th>\n",
       "      <th>11</th>\n",
       "      <th>21</th>\n",
       "      <th>31</th>\n",
       "      <th>41</th>\n",
       "      <th>51</th>\n",
       "      <th>61</th>\n",
       "      <th>71</th>\n",
       "      <th>81</th>\n",
       "      <th>...</th>\n",
       "      <th>891</th>\n",
       "      <th>901</th>\n",
       "      <th>911</th>\n",
       "      <th>921</th>\n",
       "      <th>931</th>\n",
       "      <th>941</th>\n",
       "      <th>951</th>\n",
       "      <th>961</th>\n",
       "      <th>971</th>\n",
       "      <th>981</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ERR1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ERR2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ERR3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ERR4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ERR5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  run_accession  1  11  21  31  41  51  61  71  81  ...  891  901  911  921  \\\n",
       "0          ERR1  0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "1          ERR2  0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "2          ERR3  0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "3          ERR4  0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "4          ERR5  0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
       "\n",
       "   931  941  951  961  971  981  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "### study selectios\n",
    "df_studies=pd.read_csv(\"study_dummydata.csv\")\n",
    "df_studies_adj=df_studies[[\"wgs_id\",\"study_country_concat\",drug]]\n",
    "\n",
    "##### load genetable\n",
    "df_gff = pd.read_csv(\"gff_dummydata.csv\",sep=',')  ###this is a gff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "####prepare the entire dataset (e.g. before subsetting on a specific study\n",
    "dm=prepare_dataset(df_studies_adj,df,list_of_studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_names,feature_genes=extract_gene_from_columnname(dm)\n",
    "if verbose==1:\n",
    "    print(feature_genes[0:50],\"genes of first 50 SNPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeneA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GeneA</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SNP\n",
       "GeneA   15"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SNP_table_dict={}\n",
    "for i in gene_table_list: \n",
    "    print(i)\n",
    "    df_check_variants=dm.filter(regex=i)\n",
    "    df_check_variants=df_check_variants.astype(int)\n",
    "    SNP_table_dict[i]=sum(df_check_variants.sum(axis=0)>0)\n",
    "\n",
    "df_snp_table=pd.DataFrame.from_dict(SNP_table_dict, orient='index')\n",
    "df_snp_table.columns=[\"SNP\"]\n",
    "title=drug_short+\"_snp_table.csv\"\n",
    "df_snp_table.to_csv(title)\n",
    "df_snp_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  70 out of  70 | elapsed:    0.1s finished\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "{'max_depth': 4}\n",
      "{'mean_test_score': array([0.50378931, 0.50567467, 0.50940089, 0.48144042, 0.48190763,\n",
      "       0.48284204, 0.48358097, 0.48514867, 0.48076413, 0.48236341,\n",
      "       0.48236341, 0.48310234, 0.47948349, 0.47123551]), 'std_test_score': array([0.00855329, 0.00811678, 0.00837889, 0.04327531, 0.04247836,\n",
      "       0.04090191, 0.04105403, 0.04122576, 0.03883951, 0.0382187 ,\n",
      "       0.0382187 , 0.03849724, 0.04880442, 0.04614639])}\n",
      "4\n",
      "{'max_depth': 4}\n",
      "Best: 0.509401 using {'max_depth': 4}\n",
      "[0.50378931 0.50567467 0.50940089 0.48144042 0.48190763 0.48284204\n",
      " 0.48358097 0.48514867 0.48076413 0.48236341 0.48236341 0.48310234\n",
      " 0.47948349 0.47123551] means\n",
      "0.503789 (0.008553) with: {'max_depth': 2}\n",
      "0.505675 (0.008117) with: {'max_depth': 3}\n",
      "0.509401 (0.008379) with: {'max_depth': 4}\n",
      "0.481440 (0.043275) with: {'max_depth': 5}\n",
      "0.481908 (0.042478) with: {'max_depth': 6}\n",
      "0.482842 (0.040902) with: {'max_depth': 7}\n",
      "0.483581 (0.041054) with: {'max_depth': 8}\n",
      "0.485149 (0.041226) with: {'max_depth': 9}\n",
      "0.480764 (0.038840) with: {'max_depth': 10}\n",
      "0.482363 (0.038219) with: {'max_depth': 11}\n",
      "0.482363 (0.038219) with: {'max_depth': 12}\n",
      "0.483102 (0.038497) with: {'max_depth': 13}\n",
      "0.479483 (0.048804) with: {'max_depth': 14}\n",
      "0.471236 (0.046146) with: {'max_depth': 15}\n",
      "0.9287211740041929 accuracy score on training data\n",
      "0.5233644859813084 roc auc score\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"486pt\" height=\"552pt\"\n",
       " viewBox=\"0.00 0.00 486.00 552.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 548)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-548 482,-548 482,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#e78b49\" stroke=\"#000000\" d=\"M405,-544C405,-544 293,-544 293,-544 287,-544 281,-538 281,-532 281,-532 281,-473 281,-473 281,-467 287,-461 293,-461 293,-461 405,-461 405,-461 411,-461 417,-467 417,-473 417,-473 417,-532 417,-532 417,-538 411,-544 405,-544\"/>\n",
       "<text text-anchor=\"start\" x=\"289\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">GeneC_421.0 â‰¤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"313.5\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.138</text>\n",
       "<text text-anchor=\"start\" x=\"300.5\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1431</text>\n",
       "<text text-anchor=\"start\" x=\"291\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1324, 107]</text>\n",
       "<text text-anchor=\"start\" x=\"299\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = sensitive</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#e78b49\" stroke=\"#000000\" d=\"M334,-425C334,-425 222,-425 222,-425 216,-425 210,-419 210,-413 210,-413 210,-354 210,-354 210,-348 216,-342 222,-342 222,-342 334,-342 334,-342 340,-342 346,-348 346,-354 346,-354 346,-413 346,-413 346,-419 340,-425 334,-425\"/>\n",
       "<text text-anchor=\"start\" x=\"218\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">GeneD_671.0 â‰¤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"242.5\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.136</text>\n",
       "<text text-anchor=\"start\" x=\"229.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1429</text>\n",
       "<text text-anchor=\"start\" x=\"220\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1324, 105]</text>\n",
       "<text text-anchor=\"start\" x=\"228\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = sensitive</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M324.1676,-460.8796C319.0091,-452.2335 313.5192,-443.0322 308.1924,-434.1042\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"311.0678,-432.0924 302.9383,-425.2981 305.0564,-435.679 311.0678,-432.0924\"/>\n",
       "<text text-anchor=\"middle\" x=\"296.8149\" y=\"-445.8366\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<path fill=\"#399de5\" stroke=\"#000000\" d=\"M466,-417.5C466,-417.5 376,-417.5 376,-417.5 370,-417.5 364,-411.5 364,-405.5 364,-405.5 364,-361.5 364,-361.5 364,-355.5 370,-349.5 376,-349.5 376,-349.5 466,-349.5 466,-349.5 472,-349.5 478,-355.5 478,-361.5 478,-361.5 478,-405.5 478,-405.5 478,-411.5 472,-417.5 466,-417.5\"/>\n",
       "<text text-anchor=\"start\" x=\"393\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"383.5\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n",
       "<text text-anchor=\"start\" x=\"381.5\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 2]</text>\n",
       "<text text-anchor=\"start\" x=\"372\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = resistant</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>0&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M374.1821,-460.8796C380.9017,-449.7735 388.1757,-437.7513 394.9414,-426.5691\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"398.0559,-428.1826 400.238,-417.8149 392.0668,-424.5589 398.0559,-428.1826\"/>\n",
       "<text text-anchor=\"middle\" x=\"406.2117\" y=\"-438.3908\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#e78b49\" stroke=\"#000000\" d=\"M263,-306C263,-306 151,-306 151,-306 145,-306 139,-300 139,-294 139,-294 139,-235 139,-235 139,-229 145,-223 151,-223 151,-223 263,-223 263,-223 269,-223 275,-229 275,-235 275,-235 275,-294 275,-294 275,-300 269,-306 263,-306\"/>\n",
       "<text text-anchor=\"start\" x=\"147\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">GeneD_681.0 â‰¤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"171.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.135</text>\n",
       "<text text-anchor=\"start\" x=\"158.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1428</text>\n",
       "<text text-anchor=\"start\" x=\"149\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1324, 104]</text>\n",
       "<text text-anchor=\"start\" x=\"157\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = sensitive</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M253.1676,-341.8796C248.0091,-333.2335 242.5192,-324.0322 237.1924,-315.1042\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"240.0678,-313.0924 231.9383,-306.2981 234.0564,-316.679 240.0678,-313.0924\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<path fill=\"#399de5\" stroke=\"#000000\" d=\"M395,-298.5C395,-298.5 305,-298.5 305,-298.5 299,-298.5 293,-292.5 293,-286.5 293,-286.5 293,-242.5 293,-242.5 293,-236.5 299,-230.5 305,-230.5 305,-230.5 395,-230.5 395,-230.5 401,-230.5 407,-236.5 407,-242.5 407,-242.5 407,-286.5 407,-286.5 407,-292.5 401,-298.5 395,-298.5\"/>\n",
       "<text text-anchor=\"start\" x=\"322\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"310.5\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"301\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = resistant</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>1&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M303.1821,-341.8796C309.9017,-330.7735 317.1757,-318.7513 323.9414,-307.5691\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"327.0559,-309.1826 329.238,-298.8149 321.0668,-305.5589 327.0559,-309.1826\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#e78b48\" stroke=\"#000000\" d=\"M191.5,-187C191.5,-187 80.5,-187 80.5,-187 74.5,-187 68.5,-181 68.5,-175 68.5,-175 68.5,-116 68.5,-116 68.5,-110 74.5,-104 80.5,-104 80.5,-104 191.5,-104 191.5,-104 197.5,-104 203.5,-110 203.5,-116 203.5,-116 203.5,-175 203.5,-175 203.5,-181 197.5,-187 191.5,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"76.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">GeneE_881.0 â‰¤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"100.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.134</text>\n",
       "<text text-anchor=\"start\" x=\"87.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1427</text>\n",
       "<text text-anchor=\"start\" x=\"78\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1324, 103]</text>\n",
       "<text text-anchor=\"start\" x=\"86\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = sensitive</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M182.1676,-222.8796C177.0091,-214.2335 171.5192,-205.0322 166.1924,-196.1042\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"169.0678,-194.0924 160.9383,-187.2981 163.0564,-197.679 169.0678,-194.0924\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#399de5\" stroke=\"#000000\" d=\"M324,-179.5C324,-179.5 234,-179.5 234,-179.5 228,-179.5 222,-173.5 222,-167.5 222,-167.5 222,-123.5 222,-123.5 222,-117.5 228,-111.5 234,-111.5 234,-111.5 324,-111.5 324,-111.5 330,-111.5 336,-117.5 336,-123.5 336,-123.5 336,-167.5 336,-167.5 336,-173.5 330,-179.5 324,-179.5\"/>\n",
       "<text text-anchor=\"start\" x=\"251\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"241.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"239.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"230\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = resistant</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M232.1821,-222.8796C238.9017,-211.7735 246.1757,-199.7513 252.9414,-188.5691\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"256.0559,-190.1826 258.238,-179.8149 250.0668,-186.5589 256.0559,-190.1826\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#e78b48\" stroke=\"#000000\" d=\"M120,-68C120,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 120,0 120,0 126,0 132,-6 132,-12 132,-12 132,-56 132,-56 132,-62 126,-68 120,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"30.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.133</text>\n",
       "<text text-anchor=\"start\" x=\"17.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1426</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1324, 102]</text>\n",
       "<text text-anchor=\"start\" x=\"16\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = sensitive</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M109.9346,-103.9815C104.3955,-95.1585 98.5364,-85.8258 92.9645,-76.9506\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"95.7922,-74.872 87.5108,-68.2637 89.8637,-78.594 95.7922,-74.872\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#399de5\" stroke=\"#000000\" d=\"M252,-68C252,-68 162,-68 162,-68 156,-68 150,-62 150,-56 150,-56 150,-12 150,-12 150,-6 156,0 162,0 162,0 252,0 252,0 258,0 264,-6 264,-12 264,-12 264,-56 264,-56 264,-62 258,-68 252,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"179\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"169.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"167.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"158\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = resistant</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>3&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M162.4378,-103.9815C168.056,-95.1585 173.9988,-85.8258 179.6503,-76.9506\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"182.7629,-78.5787 185.1819,-68.2637 176.8584,-74.8188 182.7629,-78.5787\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f4b51c7fac8>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "####fit regular tree on entire dataset\n",
    "y,X,columns_of_df= subset_study(dm,list_of_studies,drug)\n",
    "X_train, X_test, y_train, y_test=split_dataset_train_test(X, y, test_size_percentage,verbose=0,seednumber=seednumber)\n",
    "\n",
    "if cross_validate==1:\n",
    "    max_depth_setting=cross_validation_regular_tree(number_cross_val_splits,1,1,scoring_metric,max_depth_cross_val_list)\n",
    "else:\n",
    "    max_depth_setting=fixed_max_depth\n",
    "\n",
    "###fit tree\n",
    "clf = tree.DecisionTreeClassifier(max_depth=max_depth_setting,criterion=\"gini\",splitter=\"best\",min_samples_leaf=1,random_state=seednumber)\n",
    "\n",
    "if train_on_full_dataset==1:\n",
    "    clf=fit_model(clf,X_input=X,y_input=y,show_accuracy=1)\n",
    "    predictions_prob,predictions_binary,cm=make_predictions(clf,X_to_test=X,y_to_compare=y) \n",
    "    TPR,TNR,PPV,NPV,FPR,FNR,FDR,ACC=get_metrics_predictions(cm)\n",
    "    roc_score=get_roc_score(y, predictions_prob)\n",
    "else:\n",
    "    clf=fit_model(clf,X_input=X_train,y_input=y_train,show_accuracy=1)\n",
    "    predictions_prob,predictions_binary,cm=make_predictions(clf,X_to_test=X_test,y_to_compare=y_test)\n",
    "    TPR,TNR,PPV,NPV,FPR,FNR,FDR,ACC=get_metrics_predictions(cm)\n",
    "    roc_score=get_roc_score(y_test, predictions_prob)\n",
    "\n",
    "perf_dict[\"regtree_sens\"]=TPR;perf_dict[\"regtree_spec\"]=TNR;perf_dict[\"regtree_acc\"]=ACC;perf_dict[\"regtree_AUC\"]=roc_score\n",
    "\n",
    "plot_tree(clf, features_names, show_node_types=False, show_id=False,title_graph=str(drug_title)+\"_regular_tree_entire_dataset\")  ###plot tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9273235499650594 accuracy score on training data\n",
      "0.514018691588785 roc auc score\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"344pt\" height=\"314pt\"\n",
       " viewBox=\"0.00 0.00 344.00 314.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 310)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-310 340,-310 340,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#e78b49\" stroke=\"#000000\" d=\"M263,-306C263,-306 151,-306 151,-306 145,-306 139,-300 139,-294 139,-294 139,-235 139,-235 139,-229 145,-223 151,-223 151,-223 263,-223 263,-223 269,-223 275,-229 275,-235 275,-235 275,-294 275,-294 275,-300 269,-306 263,-306\"/>\n",
       "<text text-anchor=\"start\" x=\"147\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">GeneC_421.0 â‰¤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"171.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.138</text>\n",
       "<text text-anchor=\"start\" x=\"158.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1431</text>\n",
       "<text text-anchor=\"start\" x=\"149\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1324, 107]</text>\n",
       "<text text-anchor=\"start\" x=\"157\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = sensitive</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#e78b49\" stroke=\"#000000\" d=\"M191.5,-187C191.5,-187 80.5,-187 80.5,-187 74.5,-187 68.5,-181 68.5,-175 68.5,-175 68.5,-116 68.5,-116 68.5,-110 74.5,-104 80.5,-104 80.5,-104 191.5,-104 191.5,-104 197.5,-104 203.5,-110 203.5,-116 203.5,-116 203.5,-175 203.5,-175 203.5,-181 197.5,-187 191.5,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"76.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">GeneA_121.0 â‰¤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"100.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.136</text>\n",
       "<text text-anchor=\"start\" x=\"87.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1429</text>\n",
       "<text text-anchor=\"start\" x=\"78\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1324, 105]</text>\n",
       "<text text-anchor=\"start\" x=\"86\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = sensitive</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M182.1676,-222.8796C177.0091,-214.2335 171.5192,-205.0322 166.1924,-196.1042\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"169.0678,-194.0924 160.9383,-187.2981 163.0564,-197.679 169.0678,-194.0924\"/>\n",
       "<text text-anchor=\"middle\" x=\"154.8149\" y=\"-207.8366\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 120 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>120</title>\n",
       "<path fill=\"#399de5\" stroke=\"#000000\" d=\"M324,-179.5C324,-179.5 234,-179.5 234,-179.5 228,-179.5 222,-173.5 222,-167.5 222,-167.5 222,-123.5 222,-123.5 222,-117.5 228,-111.5 234,-111.5 234,-111.5 324,-111.5 324,-111.5 330,-111.5 336,-117.5 336,-123.5 336,-123.5 336,-167.5 336,-167.5 336,-173.5 330,-179.5 324,-179.5\"/>\n",
       "<text text-anchor=\"start\" x=\"251\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"241.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n",
       "<text text-anchor=\"start\" x=\"239.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 2]</text>\n",
       "<text text-anchor=\"start\" x=\"230\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = resistant</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;120 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;120</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M232.1821,-222.8796C238.9017,-211.7735 246.1757,-199.7513 252.9414,-188.5691\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"256.0559,-190.1826 258.238,-179.8149 250.0668,-186.5589 256.0559,-190.1826\"/>\n",
       "<text text-anchor=\"middle\" x=\"264.2117\" y=\"-200.3908\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#e78b49\" stroke=\"#000000\" d=\"M120,-68C120,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 120,0 120,0 126,0 132,-6 132,-12 132,-12 132,-56 132,-56 132,-62 126,-68 120,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"30.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.135</text>\n",
       "<text text-anchor=\"start\" x=\"17.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1428</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1324, 104]</text>\n",
       "<text text-anchor=\"start\" x=\"16\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = sensitive</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M109.9346,-103.9815C104.3955,-95.1585 98.5364,-85.8258 92.9645,-76.9506\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"95.7922,-74.872 87.5108,-68.2637 89.8637,-78.594 95.7922,-74.872\"/>\n",
       "</g>\n",
       "<!-- 119 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>119</title>\n",
       "<path fill=\"#399de5\" stroke=\"#000000\" d=\"M252,-68C252,-68 162,-68 162,-68 156,-68 150,-62 150,-56 150,-56 150,-12 150,-12 150,-6 156,0 162,0 162,0 252,0 252,0 258,0 264,-6 264,-12 264,-12 264,-56 264,-56 264,-62 258,-68 252,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"179\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"169.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"167.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"158\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = resistant</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;119 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;119</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M162.4378,-103.9815C168.056,-95.1585 173.9988,-85.8258 179.6503,-76.9506\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"182.7629,-78.5787 185.1819,-68.2637 176.8584,-74.8188 182.7629,-78.5787\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f4b58c0ee80>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "max_depth_setting=fixed_max_depth\n",
    "\n",
    "clf = ShortListDecisionTreeClassifier(criterion=\"gini\", splitter='new_best',class_weight=weights, min_samples_leaf=1, feature_genes=feature_genes,\n",
    "                                      short_list=prior_list, max_difference=max_difference)\n",
    "\n",
    "if train_on_full_dataset==1:\n",
    "    clf=fit_model(clf,X_input=X,y_input=y,show_accuracy=1)\n",
    "    predictions_prob,predictions_binary,cm=make_predictions(clf,X_to_test=X,y_to_compare=y)   \n",
    "    TPR,TNR,PPV,NPV,FPR,FNR,FDR,ACC=get_metrics_predictions(cm)\n",
    "    roc_score=get_roc_score(y, predictions_prob)\n",
    "else:\n",
    "    clf=fit_model(clf,X_input=X_train,y_input=y_train,show_accuracy=1)\n",
    "    predictions_prob,predictions_binary,cm=make_predictions(clf,X_to_test=X_train,y_to_compare=y_test)\n",
    "    TPR,TNR,PPV,NPV,FPR,FNR,FDR,ACC=get_metrics_predictions(cm)\n",
    "    roc_score=get_roc_score(y_test, predictions_prob)\n",
    "\n",
    "perf_dict[\"TBtree_sens\"]=TPR;perf_dict[\"TBtree_spec\"]=TNR;perf_dict[\"TBtree_acc\"]=ACC;perf_dict[\"TBtree_AUC\"]=roc_score\n",
    "\n",
    "plot_tree(clf, features_names, show_node_types=False, show_id=False,title_graph=str(drug_title)+\"Tbtree_entire_dataset\") ###plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study1 study\n",
      "0.96 accuracy score on training data\n",
      "0.50625 roc auc score\n",
      "            SNP  importance_Study1\n",
      "0   GeneD_641.0           0.236366\n",
      "1   GeneE_941.0           0.000000\n",
      "2   GeneA_141.0           0.164788\n",
      "3    GeneA_71.0           0.167534\n",
      "4   GeneE_891.0           0.170350\n",
      "5     GeneA_1.0           0.086253\n",
      "6   GeneE_901.0           0.086984\n",
      "7   GeneE_951.0           0.087724\n",
      "8   GeneE_971.0           0.000000\n",
      "9   GeneE_971.0           0.000000\n",
      "10  GeneE_971.0           0.000000\n",
      "11  GeneE_971.0           0.000000\n",
      "12  GeneE_971.0           0.000000\n",
      "13  GeneE_971.0           0.000000\n",
      "14  GeneE_971.0           0.000000\n",
      "15  GeneE_971.0           0.000000\n",
      "16  GeneE_971.0           0.000000\n",
      "[1, 2, 4, 0] indexbool\n",
      "Study2 study\n",
      "0.9217391304347826 accuracy score on training data\n",
      "0.5588666065795403 roc auc score\n",
      "            SNP  importance_Study2\n",
      "0   GeneE_881.0           0.722596\n",
      "1   GeneE_981.0           0.171198\n",
      "2   GeneC_461.0           0.000000\n",
      "3   GeneA_151.0           0.004507\n",
      "4   GeneA_161.0           0.004535\n",
      "5   GeneA_191.0           0.004564\n",
      "6    GeneA_21.0           0.004593\n",
      "7    GeneA_41.0           0.004623\n",
      "8    GeneA_91.0           0.004653\n",
      "9   GeneB_251.0           0.004683\n",
      "10  GeneB_261.0           0.004713\n",
      "11  GeneB_271.0           0.004744\n",
      "12  GeneB_311.0           0.004774\n",
      "13  GeneB_371.0           0.004806\n",
      "14  GeneB_391.0           0.004837\n",
      "15  GeneC_401.0           0.004869\n",
      "16  GeneC_521.0           0.004901\n",
      "17  GeneC_531.0           0.004934\n",
      "18  GeneC_551.0           0.004966\n",
      "19  GeneD_631.0           0.004999\n",
      "20  GeneD_651.0           0.005033\n",
      "21  GeneD_661.0           0.005067\n",
      "22  GeneD_711.0           0.005101\n",
      "23  GeneE_891.0           0.005135\n",
      "24  GeneE_941.0           0.005170\n",
      "25  GeneE_971.0           0.000000\n",
      "26  GeneE_971.0           0.000000\n",
      "27  GeneE_971.0           0.000000\n",
      "28  GeneE_971.0           0.000000\n",
      "29  GeneE_971.0           0.000000\n",
      "30  GeneE_971.0           0.000000\n",
      "31  GeneE_971.0           0.000000\n",
      "32  GeneE_971.0           0.000000\n",
      "33  GeneE_971.0           0.000000\n",
      "34  GeneE_971.0           0.000000\n",
      "35  GeneE_971.0           0.000000\n",
      "36  GeneE_971.0           0.000000\n",
      "37  GeneE_971.0           0.000000\n",
      "38  GeneE_971.0           0.000000\n",
      "39  GeneE_971.0           0.000000\n",
      "40  GeneE_971.0           0.000000\n",
      "41  GeneE_971.0           0.000000\n",
      "42  GeneE_971.0           0.000000\n",
      "43  GeneE_971.0           0.000000\n",
      "44  GeneE_971.0           0.000000\n",
      "45  GeneE_971.0           0.000000\n",
      "46  GeneE_971.0           0.000000\n",
      "47  GeneE_971.0           0.000000\n",
      "48  GeneE_971.0           0.000000\n",
      "49  GeneC_501.0           0.000000\n",
      "50  GeneE_971.0           0.000000\n",
      "51  GeneE_971.0           0.000000\n",
      "52  GeneE_971.0           0.000000\n",
      "[2, 3, 4, 5, 6, 7, 0] indexbool\n",
      "Study3 study\n",
      "0.9375 accuracy score on training data\n",
      "0.5555555555555556 roc auc score\n",
      "            SNP  importance_Study3\n",
      "0   GeneA_121.0           0.319948\n",
      "1   GeneD_661.0           0.321623\n",
      "2   GeneD_681.0           0.323312\n",
      "3   GeneE_941.0           0.000000\n",
      "4   GeneB_201.0           0.003107\n",
      "5   GeneB_311.0           0.003141\n",
      "6    GeneA_11.0           0.001583\n",
      "7    GeneA_41.0           0.001592\n",
      "8    GeneA_81.0           0.001601\n",
      "9   GeneB_251.0           0.001609\n",
      "10  GeneB_331.0           0.001618\n",
      "11  GeneB_341.0           0.001627\n",
      "12  GeneB_371.0           0.001636\n",
      "13  GeneC_451.0           0.001646\n",
      "14  GeneC_481.0           0.001655\n",
      "15  GeneC_561.0           0.001664\n",
      "16  GeneD_611.0           0.001673\n",
      "17  GeneD_691.0           0.001683\n",
      "18  GeneD_701.0           0.001692\n",
      "19  GeneD_711.0           0.001702\n",
      "20  GeneD_751.0           0.001712\n",
      "21  GeneE_811.0           0.001721\n",
      "22  GeneE_931.0           0.001731\n",
      "23  GeneE_981.0           0.000723\n",
      "24  GeneE_971.0           0.000000\n",
      "25  GeneE_971.0           0.000000\n",
      "26  GeneE_971.0           0.000000\n",
      "27  GeneE_971.0           0.000000\n",
      "28  GeneE_971.0           0.000000\n",
      "29  GeneE_971.0           0.000000\n",
      "30  GeneE_971.0           0.000000\n",
      "31  GeneE_971.0           0.000000\n",
      "32  GeneE_971.0           0.000000\n",
      "33  GeneE_971.0           0.000000\n",
      "34  GeneE_971.0           0.000000\n",
      "35  GeneE_971.0           0.000000\n",
      "36  GeneE_971.0           0.000000\n",
      "37  GeneE_971.0           0.000000\n",
      "38  GeneE_971.0           0.000000\n",
      "39  GeneE_971.0           0.000000\n",
      "40  GeneE_971.0           0.000000\n",
      "41  GeneE_971.0           0.000000\n",
      "42  GeneE_971.0           0.000000\n",
      "43  GeneE_971.0           0.000000\n",
      "44  GeneE_971.0           0.000000\n",
      "45  GeneE_971.0           0.000000\n",
      "46  GeneE_971.0           0.000000\n",
      "47  GeneE_971.0           0.000000\n",
      "48  GeneE_971.0           0.000000\n",
      "[0, 5, 6, 7, 1] indexbool\n",
      "Study4 study\n",
      "0.9391534391534392 accuracy score on training data\n",
      "0.5208333333333334 roc auc score\n",
      "            SNP  importance_Study4\n",
      "0   GeneD_671.0           0.924870\n",
      "1   GeneE_981.0           0.000000\n",
      "2   GeneE_941.0           0.013407\n",
      "3   GeneB_391.0           0.009072\n",
      "4   GeneA_171.0           0.004577\n",
      "5    GeneA_51.0           0.004604\n",
      "6    GeneA_61.0           0.004632\n",
      "7   GeneB_251.0           0.004660\n",
      "8   GeneB_281.0           0.004689\n",
      "9   GeneB_311.0           0.004717\n",
      "10  GeneB_371.0           0.004746\n",
      "11  GeneD_721.0           0.004775\n",
      "12  GeneD_741.0           0.004805\n",
      "13  GeneE_811.0           0.004834\n",
      "14  GeneE_861.0           0.004864\n",
      "15  GeneE_971.0           0.000000\n",
      "16  GeneE_971.0           0.000000\n",
      "17  GeneE_971.0           0.000000\n",
      "18  GeneE_971.0           0.000000\n",
      "19  GeneE_971.0           0.000000\n",
      "20  GeneE_971.0           0.000000\n",
      "21  GeneE_971.0           0.000000\n",
      "22  GeneE_971.0           0.000000\n",
      "23  GeneE_971.0           0.000000\n",
      "24  GeneE_971.0           0.000000\n",
      "25  GeneE_971.0           0.000000\n",
      "26  GeneE_971.0           0.000000\n",
      "27  GeneE_971.0           0.000000\n",
      "28  GeneE_971.0           0.000000\n",
      "29  GeneD_611.0           0.000748\n",
      "30  GeneE_971.0           0.000000\n",
      "31  GeneE_971.0           0.000000\n",
      "32  GeneE_971.0           0.000000\n",
      "[3, 4, 5, 0] indexbool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/storage2/wouter/anaconda2/envs/py3/lib/python3.6/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/opt/storage2/wouter/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:592: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/storage2/wouter/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:600: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/storage2/wouter/anaconda2/envs/py3/lib/python3.6/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/opt/storage2/wouter/anaconda2/envs/py3/lib/python3.6/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/opt/storage2/wouter/anaconda2/envs/py3/lib/python3.6/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study5 study\n",
      "0.7837837837837838 accuracy score on training data\n",
      "0.5555555555555556 roc auc score\n",
      "            SNP  importance_Study5\n",
      "0   GeneC_421.0           0.481117\n",
      "1   GeneD_711.0           0.000000\n",
      "2   GeneE_931.0           0.257886\n",
      "3   GeneE_981.0           0.127152\n",
      "4   GeneE_891.0           0.041689\n",
      "5   GeneB_251.0           0.021887\n",
      "6   GeneB_351.0           0.022629\n",
      "7   GeneD_621.0           0.023409\n",
      "8   GeneD_731.0           0.024230\n",
      "9   GeneE_971.0           0.000000\n",
      "10  GeneE_971.0           0.000000\n",
      "11  GeneE_971.0           0.000000\n",
      "12  GeneE_971.0           0.000000\n",
      "13  GeneE_971.0           0.000000\n",
      "14  GeneE_971.0           0.000000\n",
      "15  GeneE_971.0           0.000000\n",
      "16  GeneE_971.0           0.000000\n",
      "17  GeneE_971.0           0.000000\n",
      "18  GeneE_971.0           0.000000\n",
      "[0] indexbool\n",
      "Index(['Study1', 'Study2', 'Study3', 'Study4', 'Study5'], dtype='object') columns check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/storage2/wouter/anaconda2/envs/py3/lib/python3.6/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsQAAAInCAYAAACfhU+vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdf5he9Xnf+fenkoyAFgiCYgGhgoLiWoSYyPIKC4OAlPxY1gEjO2izxHaJoQq2a3CyZHuZpE1LXRY3hnCRgIqpSQuur0AWXNtBgQAmuAQhFIElg2IKgsyaLGAsklSAjHLvH893kuPxo5kRo5Fm5nm/rmsunfM93x/3OfYft29/z3lSVUiSJEmD6u/t7QAkSZKkvcmEWJIkSQPNhFiSJEkDzYRYkiRJA82EWJIkSQPNhFiSJEkDzYRYkiRJA82EeA9IsiXJq0n+uvN3eJIFSWpE+18n+bkR4/9V6/euTtu/7PR/LcmOzvmmztyzR8z1+ST/th1/qDPuL5M8luSsTt9xxdfpf3+SX2zHy9vY60b0eTDJhzrn85N8LsnzSf4qyZNJ/nWS/dv1SnJsn7X+VZL/0qf9b/snWZTkD5N8N8nWJI8m+ZlOfEMjxp6VZG2S/5nkO0luSXJk5/qH2vy/MmLcUJLl/Z6JJEma+kyI95z/rar+fufv251rB4249sXhC0kCnA+8DHxwuL2q/t1wf+CfAw91xi/ahbgeanMcBPw28F+THDSiz07jG8P/BH4hyYJ+F5McDDwE7AucVFX/APinLZZ/vAv3sDP/DbgbOAz4h8DHgb/cSSwrgFuBa4BDgEXA68CDSX6o0/Vl4LIkB+yG+CRJ0hRgQjz1vQc4HPgXwHlJ3jIZi1TV3wD/GdgfOG43TbsV+Dzw6zu5finwV8D/UVVbWhx/XlX/oqoen8jCSQ4Bjgb+Y1Vtb39fr6oH+/QN8B+Af1tVt1TVq1X1F8AvAn8NXNLp/gS9JP6SkfNIkqTpyYR46vsgvUrncFX2rFH6vmlJZgEfBr4HPLsbp74CODfJj/S59hPA77dkfHf7DvAU8F+SnJ3ksFH6/ghwFPB73cYW1+30qtZdlwOXtAq3JEma5kyI95w72j7WrUnuGHHtpc61rUn+CUCS/YD3A7dW1feA2+hsm9hNlibZCrwGfIZetfaF8cQ3Hq3Sej3wG30uzwOef7OBj7FuAacBW+hVf59P8kCSftXvQ9q//WJ5vnN9eO4NwB8Cl+22gCVJ0l5jQrznnF1VB7W/s0dcO6Rz7aCqeqK1nwO8AXy1nd8C/HSSQ8ex3hvt3zkj2ufQqwIP+5OqOgj4IeBL9LZojLSz+MbrSuAnk/zYiPbvAPN3ca5hbzDi3pIMn38PoKqGquqjVfWPgX9Eb0/z7/aZ66X2b79Y5neud/0asCrJW99E7JIkaQoxIZ7aPgj8feC5JH9B7//SnwOsHMfY5+klhgtGtB9Nny0RVfXXwC8B5yc5cQIx/4Cq+g5wNfBvRly6BzgnyZv57+Fz9L+3HcD/2yeGPweuA47vM9dmYIheNf5vtbjOBf6oz3xPAr8P/MtdD12SJE0lJsRTVJIjgDPo7Rl+R/v7MXrV1jG3TVTVDnr7X69IMi/JnCQrgbcDf7CTMd8BbqRX/dzdfhN4N/BPRrQdANyc5B9B776T/GaSEzr93pJkbudvFnAX8CNJzm/3djDw74DbquqNJD/UPt92bJK/116y+2fAn/S57wJ+GfhUkv89yb6t8ntji++zO7mnf01v3/XIr3JIkqRpxIR4atg64ju/l9L71NqGqvrDqvqL4T/gt4ATkvSrdI70S/Q+E/Y48ALwUeB/rar/b5QxVwM/MyIh7RffLqmqvwT+b+DgTtvL9JLk7wEPJ/kretXYV+i9EDdsE/Bq5+/DbZ/zzwAXtXvb2MatamO206sg30PvU2sb6X1G7UM7ie+L9J75JfS2SHyT3ufglrX/odBvzDP83Zc5JEnSNJVecUySJEkaTFaIJUmSNNBMiCVJkjTQTIglSZI00EyIJUmSNNBMiCVJkjTQTIglSZI00EyIJUmSNNBMiCVJkjTQTIglSZI00EyIJUmSNNBMiCVJkjTQTIglSZI00EyIJUmSNNBMiCVJkjTQTIglSZI00EyIJUmSNNBMiCVJkjTQTIglSZI00EyIJUmSNNBMiCVJkjTQZu/tAGa6F197vvZ2DJp8h86dv7dDkCRJY0u/RivEkiRJGmgmxJIkSRpoJsSSJEkaaCbEkiRJGmgmxJIkSRpoJsSSJEkaaCbEkiRJGmgmxJIkSRpok5YQJzksya1Jnk7yaJKHkpwzSWvNTvJSkk+P0e/qJKe0448meSpJJTlklDEfTPKt9vfBTvs9SX5o992FJEmS9oZJSYiTBLgDeKCqjqmqxcB5wJGTsR5wJrAZ+EBbu19MBwNLq+qB1vR14CeAZ3c2aRvz68D/ArwL+PVOEvyfgV/aPeFLkiRpb5msCvHpwPaqun64oaqeraprAZLMSnJVkkeSPJ7kota+PMn9SW5L8mSSW4YT3CSLk3ytVZvXJOn+Vu5K4BrgOWDpTmJaAdzViedPq2rLGPfxk8DdVfVyVX0XuBv4qXbtS21dSZIkTWOTlRAvAtaPcv0C4JWqWgIsAT6S5Oh27UTgE8DbgWOAZUnmANcCK1q1+SbgCoAk+wJnAF8GvsDOk9RlwKO7eB9HAH/eOR9qbbQEeZ8k80YOSnJhknVJ1v3u5/7LLi4pSZKkPWn2nlgkyXXAyfSqxkvobXE4IcmK1uVA4DhgO7C2qobauA3AAmArcDxwdysYzwKeb2PPAu6rqm1JbgcuT3JJVe0YEcZ84MVdDb1PW3WOXwAOB77zfR2qVgOrAV587fluf0mSJE0xk5UQbwLOHT6pqovbi2vrWlOAj1XVmu6gJMuB1ztNO1qMATZV1Ul91lpJr4q8pZ3PA04D7hnR71Vg7i7exxCwvHN+JHB/53xum1eSJEnT1GRtmbgXmJtkVadtv87xGmBV2wpBkoVJ9h9lvs3AoUlOav3nJFmU5AB6leejqmpBVS0ALqb/tokngGN38T7WAGcm+aH2Mt2ZrW34xcG3Alt2cU5JkiRNIZOSEFdVAWcDpyZ5Jsla4GbgstblRuCbwPokG4EbGKVaXVXb6b0Ud2WSx4ANwLuB9wH3VlW3qnwn8N4k+4yY5it0qr1JPp5kiF7V9/EkN7b2dw4fV9XLwL8BHml/v9HaABYDf1JVb4z/yUiSJGmqSS93HQxJHgTOqqqtu2Gua4AvVdUfjdbPPcSD4dC588fuJEmS9ra+n+cdtF+q+yRw1G6aa+NYybAkSZKmvoGqEO8NVogHgxViSZKmBSvEkiRJ0kgmxJIkSRpoJsSSJEkaaO4hnnw+YEmSpKnBPcSSJEnSSJP1082SNGO9tmPb3g5Bk2zurP3G7iRpxrBCLEmSpIFmQixJkqSBZkIsSZKkgWZCLEmSpIFmQixJkqSBZkIsSZKkgWZCLEmSpIE2oYQ4yWFJbk3ydJJHkzyU5JzdFdyItWYneSnJp8fod3WSU9rxR5M8laSSHNLp87YW6+tJfnmUuY5O8nCSbyX5YpK3dOb98O66N0mSJO09bzohThLgDuCBqjqmqhYD5wFH7q7gRjgT2Ax8oK3dL6aDgaVV9UBr+jrwE8CzI7q+DHwc+MwYa14JfLaqjgO+C1zQ2m9q4yVJkjTNTaRCfDqwvaquH26oqmer6lqAJLOSXJXkkSSPJ7motS9Pcn+S25I8meSW4QQ3yeIkX2vV5jVJ5nfWWwlcAzwHLN1JTCuAuzrx/GlVbRnZqapeqKpHgO/t7OZaTKcDt7Wmm4Gz2/htwJYk7xrtAUmSJGnqm0hCvAhYP8r1C4BXqmoJsAT4SJKj27UTgU8AbweOAZYlmQNcC6xo1eabgCsAkuwLnAF8GfgCveS4n2XAoxO4p655wNaqeqOdDwFHdK6vA97Tb2CSC5OsS7Ju9erVuykcSZIkTYbZu2uiJNcBJ9OrGi+ht8XhhCQrWpcDgeOA7cDaqhpq4zYAC4CtwPHA3a1gPAt4vo09C7ivqrYluR24PMklVbVjRBjzgRd31y31aavO8QvA2/oNrKrVwHAmXP36SJIkaWqYSEK8CTh3+KSqLm4vrq1rTQE+VlVruoOSLAde7zTtaHEE2FRVJ/VZayW9KvKWdj4POA24Z0S/V4G5b+Zm+ngJOCjJ7FYlPhL4duf63LaeJEmSprGJbJm4F5ibZFWnbb/O8RpgVdsKQZKFSfYfZb7NwKFJTmr95yRZlOQAepXno6pqQVUtAC6m/7aJJ4Bj3/QddVRVAffR25cM8EHgzk6XhcDG3bGWJEmS9p43nRC3hPFs4NQkzyRZS+/Fs8talxuBbwLrk2wEbmCUinRVbaeXfF6Z5DFgA/Bu4H3AvVXVrSrfCbw3yT4jpvkKsHz4JMnHkwzRq+4+nuTG1v7W1n4p8KkkQy3xJslXkxzeprgMuDTJU/Sq0p/rrLWMH6xQS5IkaZpJL6+dOZI8CJxVVVsncY0TgUur6vxxdJ9ZD1gSr+3YtrdD0CSbO2u/sTtJmo76frp3Jv5S3SeBoyZ5jUOAyyd5DUmSJO0BM65CPAX5gKUZxgrxzGeFWJqxBqZCLEmSJI2bCbEkSZIGmgmxJEmSBpoJsSRJkgaaL9VNPh+wJEnS1ND3pbqJ/HSzpA6/PDAY/PqAJM08bpmQJEnSQDMhliRJ0kAzIZYkSdJAMyGWJEnSQDMhliRJ0kAzIZYkSdJAMyGWJEnSQDMhliRJ0kCbUEKc5LAktyZ5OsmjSR5Kcs7uCm7EWrOTvJTk02P0uzrJKe34liSbk2xMclOSOa39bS3W15P88ihzHZ3k4STfSvLFJG9p7R9N8uHdeX+SJEnaO950QpwkwB3AA1V1TFUtBs4DjtxdwY1wJrAZ+EBbu19MBwNLq+qB1nQL8DbgR4F9gV9s7S8DHwc+M8aaVwKfrarjgO8CF7T2m9p4SZIkTXMTqRCfDmyvquuHG6rq2aq6FiDJrCRXJXkkyeNJLmrty5Pcn+S2JE+2Km7atcVJvtaqzWuSzO+stxK4BngOWLqTmFYAd3Xi+Wo1wFpasl5VL1TVI8D3dnZzLabTgdta083A2W38NmBLkneN81lJkiRpippIQrwIWD/K9QuAV6pqCbAE+EiSo9u1E4FPAG8HjgGWte0M1wIrWrX5JuAKgCT7AmcAXwa+QC857mcZ8OjIxjb3+XSS5XGYB2ytqjfa+RBwROf6OuA9/QYmuTDJuiTrVq9evQtLSpIkaU+bvbsmSnIdcDK9qvESelscTkiyonU5EDgO2A6sraqhNm4DsADYChwP3N0KxrOA59vYs4D7qmpbktuBy5NcUlU7RoQxH3ixT3i/TW9rxx/vyi31aavO8Qv0tmP8YKeq1cBwJlz9+kiSJGlqmEhCvAk4d/ikqi5Ocgi9yin0EsqPVdWa7qAky4HXO007WhwBNlXVSX3WWkmvirylnc8DTgPuGdHvVWDuiPV+HTgUuGi8N9a8BByUZHarEh8JfLtzfW5bT5IkSdPYRLZM3AvMTbKq07Zf53gNsKrzZYeFSfYfZb7NwKFJTmr95yRZlOQAepXno6pqQVUtAC6m/7aJJ4Bjh0+S/CLwk8DKqvqbXbm5tu/4Pnr7kgE+CNzZ6bIQ2Lgrc0qSJGnqedMJcUsYzwZOTfJMkrX0Xjy7rHW5EfgmsD7JRuAGRqlIV9V2esnnlUkeAzYA7wbeB9xbVd2q8p3Ae5PsM2KarwDLO+fXA4cBDyXZkOTXAJK8NckQcCnwqSRDLfEmyVeTHN7GXwZcmuQpelXpz3XmXsYPVqglSZI0zaSX184cSR4EzqqqrZO4xonApVV1/ji6z6wHrJ16bce2vR2C9oC5s/Ybu5Mkaarq++nemfhLdZ8EjprkNQ4BLp/kNSRJkrQHzLgK8RTkAx4QVogHgxViSZrWBqZCLEmSJI2bCbEkSZIGmgmxJEmSBpp7iCefD1iSJGlqcA+xJEmSNNJEfrpZUodfmRgMc2ft53/WA8CviUiDxQqxJEmSBpoJsSRJkgaaCbEkSZIGmgmxJEmSBpoJsSRJkgaaCbEkSZIGmgmxJEmSBtqEE+IkhyW5NcnTSR5N8lCSc3ZHcH3Wmp3kpSSfHqPf1UlOGdF2bZK/7pyfkmR9kjeSrBhlrsVJvpHkqSS/lSSt/TNJTp/oPUmSJGnvmlBC3JLDO4AHquqYqloMnAccuTuC6+NMYDPwgeHEtE9MBwNLq+qBTts7gYNGdH0O+BBw6xhr/g5wIXBc+/up1n4t8Ku7GL8kSZKmmIlWiE8HtlfV9cMNVfVsVV0LkGRWkquSPJLk8SQXtfblSe5PcluSJ5Pc0qm8Lk7ytVZtXpNkfme9lcA19JLZpTuJaQVw1/BJklnAVcD/2e1UVVuq6nHgb3Z2c23tA6rqoaoq4HeBs4fvE5iX5K3jeVCSJEmamiaaEC8C1o9y/QLglapaAiwBPpLk6HbtROATwNuBY4BlSebQq7yuaNXmm4ArAJLsC5wBfBn4Ar3kuJ9lwKOd848CX6qq53f99jgCGOqcD7W2Yevbet8nyYVJ1iVZt3r16jexrCRJkvaU2btzsiTXASfTqxovobfF4YTOHt0D6W072A6sraqhNm4DsADYChwP3N0KxrOA4UT2LOC+qtqW5Hbg8iSXVNWOEWHMB15s8x4OvB9Y/mZvqU9bdY5fAA7/gQ5Vq4HVffpLkiRpiploQrwJOHf4pKouTnIIsK41BfhYVa3pDkqyHHi907SjxRJgU1Wd1GetlfSqyFva+TzgNOCeEf1eBea24xOBY4GnWoK9X5KnqurYcd7fEN+/H/pI4Nud87ltPUmSJE1TE90ycS8wN8mqTtt+neM1wKq2FYIkC5PsP8p8m4FDk5zU+s9JsijJAfQqz0dV1YKqWgBcTP9tE0/QS4Kpqq9U1Vs7Y7btQjJM22bxV0mWtj3OvwDc2emyENg43vkkSZI09UwoIW4vmp0NnJrkmSRrgZuBy1qXG4FvAuuTbARuYJSqdFVtp/dS3JVJHgM2AO8G3gfcW1XdqvKdwHuT7DNimq8wji0SSZYkGaK3peKGJJs61zZ0uq5q9/EU8D+AP2h95tBLvNchSZKkaSu9nHZmSfIgcFZVbZ3ENc4BfryqLh+j68x7wOrrtR3b9nYI2gPmztrP/6wHwNxZ+43dSdJ01PezvTP1l+o+CRw1yWvMBv7DJK8hSZKkSTYjK8RTjA94QFg1HAxWiAeDFWJpxhqoCrEkSZI0LibEkiRJGmgmxJIkSRpoJsSSJEkaaL5UN/l8wJIkSVND35fqJvrTzZIkzVh+UWTm84siArdMSJIkacCZEEuSJGmgmRBLkiRpoJkQS5IkaaCZEEuSJGmgmRBLkiRpoJkQS5IkaaCZEEuSJGmgTSghTnJYkluTPJ3k0SQPJTlndwU3Yq3ZSV5K8ukx+l2d5JR2/PkkzyTZ0P7e0drf1mJ9PckvjzLX0UkeTvKtJF9M8pbW/tEkH96d9ydJkqS9400nxEkC3AE8UFXHVNVi4DzgyN0V3AhnApuBD7S1+8V0MLC0qh7oNP9KVb2j/W1obS8DHwc+M8aaVwKfrarjgO8CF7T2m9p4SZIkTXMTqRCfDmyvquuHG6rq2aq6FiDJrCRXJXkkyeNJLmrty5Pcn+S2JE8muWU4wU2yOMnXWrV5TZL5nfVWAtcAzwFLdxLTCuCusQKvqheq6hHgezvr02I6HbitNd0MnN3GbwO2JHnXWGtJkiRpaptIQrwIWD/K9QuAV6pqCbAE+EiSo9u1E4FPAG8HjgGWJZkDXAusaNXmm4ArAJLsC5wBfBn4Ar3kuJ9lwKMj2q5oCflnk+yzC/c3D9haVW+08yHgiM71dcB7+g1McmGSdUnWrV69eheWlCRJ0p42e3dNlOQ64GR6VeMl9LY4nJBkRetyIHAcsB1YW1VDbdwGYAGwFTgeuLsVjGcBz7exZwH3VdW2JLcDlye5pKp2jAhjPvBi5/z/Av4CeAuwGrgM+I3x3lKftuocvwC8rd/Aqlrd1hs5RpIkSVPMRBLiTcC5wydVdXGSQ+hVTqGXUH6sqtZ0ByVZDrzeadrR4giwqapO6rPWSnpV5C3tfB5wGnDPiH6vAnM7MQ0n1K8n+U/ATl+g6+Ml4KAks1uV+Ejg253rc9t6kiRJmsYmsmXiXmBuklWdtv06x2uAVW0rBEkWJtl/lPk2A4cmOan1n5NkUZID6FWej6qqBVW1ALiY/tsmngCOHT4Z3oPc9gOfDWwc781VVQH30duXDPBB4M5Ol4W7Mp8kSZKmpjedELeE8Wzg1PZps7X0Xjy7rHW5EfgmsD7JRuAGRqlIV9V2esnnlUkeAzYA7wbeB9xbVd2q8p3Ae/vsCf4KsLxzfkuSbwDfAA4B/i1AkrcmGQIuBT6VZKgl3iT5apLD2/jLgEuTPEWvKv25ztzL+MEKtSRJkqaZ9PLamSPJg8BZVbV1Etc4Ebi0qs4fR/eZ9YAlaYC8tmPb3g5Bk2zurP3G7qSZpO+ne2fiL9V9Ejhqktc4BLh8kteQJEnSHjDjKsRTkA9YkqYpK8QznxXigTMwFWJJkiRp3EyIJUmSNNBMiCVJkjTQ3EM8+XzAkiRJU4N7iCVJkqSRJvLTzZIkzWh+ZWLm8ysTAivEkiRJGnAmxJIkSRpoJsSSJEkaaCbEkiRJGmgmxJIkSRpoJsSSJEkaaCbEkiRJGmgTSoiTHJbk1iRPJ3k0yUNJztldwY1Ya3aSl5J8eox+Vyc5pR0nyRVJ/izJE0k+3trf1mJ9PckvjzLX0UkeTvKtJF9M8pbW/tEkH96d9ydJkqS9400nxEkC3AE8UFXHVNVi4DzgyN0V3AhnApuBD7S1+8V0MLC0qh5oTR8Cfhh4W1X9E+C/tvaXgY8DnxljzSuBz1bVccB3gQta+01tvCRJkqa5iVSITwe2V9X1ww1V9WxVXQuQZFaSq5I8kuTxJBe19uVJ7k9yW5Ink9wynOAmWZzka63avCbJ/M56K4FrgOeApTuJaQVwV+d8FfAbVfU3Lb4Xhv+tqkeA7+3s5lpMpwO3taabgbPb+G3AliTvGsdzkiRJ0hQ2kYR4EbB+lOsXAK9U1RJgCfCRJEe3aycCnwDeDhwDLEsyB7gWWNGqzTcBVwAk2Rc4A/gy8AV6yXE/y4BHO+f/GPi5JOuS/EGS43bh/uYBW6vqjXY+BBzRub4OeE+/gUkubGuuW7169S4sKUmSpD1t9u6aKMl1wMn0qsZL6G1xOCHJitblQOA4YDuwtqqG2rgNwAJgK3A8cHcrGM8Cnm9jzwLuq6ptSW4HLk9ySVXtGBHGfODFzvk+wGtV9c4k76OXZPdNYvvdUp+26hy/ALyt38CqWg0MZ8LVr48kSZKmhokkxJuAc4dPquriJIfQq5xCL6H8WFWt6Q5Kshx4vdO0o8URYFNVndRnrZX0qshb2vk84DTgnhH9XgXmds6HgNvb8f8D/Kfx3FjzEnBQktmtSnwk8O3O9bltPUmSJE1jE9kycS8wN8mqTtt+neM1wKq2FYIkC5PsP8p8m4FDk5zU+s9JsijJAfQqz0dV1YKqWgBcTP9tE08Ax3bO76C3DxjgVODPxntzVVXAffT2JQN8ELiz02UhsHG880mSJGlqetMJcUsYzwZOTfJMkrX0Xjy7rHW5EfgmsD7JRuAGRqlIV9V2esnnlUkeAzYA7wbeB9xbVd2q8p3Ae5PsM2KarwDLO+f/Hjg3yTeATwO/CJDkrUmGgEuBTyUZaok3Sb6a5PA2/jLg0iRP0atKf64z9zJ+sEItSZKkaSa9vHbmSPIgcFZVbZ3ENU4ELq2q88fRfWY9YEkaIK/t2La3Q9Akmztrv7E7aSbp++nemfhLdZ8EjprkNQ4BLp/kNSRJkrQHzLgK8RTkA5akacoK8cxnhXjgDEyFWJIkSRo3E2JJkiQNNBNiSZIkDTQTYkmSJA00X6qbfD5gSZKkqaHvS3UT+elmjcPmV76xt0PQHvAjB/7o3g5BkiS9SW6ZkCRJ0kAzIZYkSdJAMyGWJEnSQDMhliRJ0kAzIZYkSdJAMyGWJEnSQDMhliRJ0kAzIZYkSdJAm1BCnOSwJLcmeTrJo0keSnLO7gpuxFqzk7yU5NNj9Ls6ySnt+I+TbGh/305yR2t/W4v19SS/PMpcRyd5OMm3knwxyVta+0eTfHh33p8kSZL2jjedECcJcAfwQFUdU1WLgfOAI3dXcCOcCWwGPtDW7hfTwcDSqnoAoKreU1XvqKp3AA8Bv9+6vgx8HPjMGGteCXy2qo4Dvgtc0NpvauMlSZI0zU2kQnw6sL2qrh9uqKpnq+pagCSzklyV5JEkjye5qLUvT3J/ktuSPJnkluEEN8niJF9r1eY1SeZ31lsJXAM8ByzdSUwrgLtGNib5By3eO1qcL1TVI8D3dnZzLabTgdta083A2W38NmBLkneN8YwkSZI0xU0kIV4ErB/l+gXAK1W1BFgCfCTJ0e3aicAngLcDxwDLkswBrgVWtGrzTcAVAEn2Bc4Avgx8gV5y3M8y4NE+7ecAf1RVfzn+22MesLWq3mjnQ8ARnevrgPf0G5jkwiTrkqz74udv69dFkiRJU8Ts3TVRkuuAk+lVjZfQ2+JwQpIVrcuBwHHAdmBtVQ21cRuABcBW4Hjg7lYwngU838aeBdxXVduS3A5cnuSSqtoxIoz5wIt9wlsJ3Lirt9SnrTrHLwBv6zewqlYDqwE2v/KN6tdHkiRJU8NEEuJNwLnDJ1V1cZJD6FVOoZdQfqyq1nQHJVkOvN5p2tHiCLCpqk7qs9ZKelXkLe18HnAacM+Ifq8Cc0esNw94F70q8a54CTgoyexWJT4S+Hbn+ty2niRJkqaxiWyZuBeYm2RVp22/zvEaYFXbCkGShUn2H2W+zcChSU5q/eckWZTkAHqV56OqakFVLQAupv+2iSeAY0e0vR/4clW9tgv3RlUVcB+9fckAHwTu7HRZCGzclTklSZI09bzphLgljGcDpyZ5Jslaei+eXda63Ah8E1ifZCNwA6NUpKtqO73k88okjwEbgHcD7wPurapuVflO4L1J9hkxzVeA5Xch4QsAACAASURBVCPazqO37/hvJXlrkiHgUuBTSYZa4k2SryY5vHW9DLg0yVP0qtKf60yzjB+sUEuSJGmaSS+vnTmSPAicVVVbJ3GNE4FLq+r8sfq6h3gw/MiBP7q3Q5AkSWPr++nemfhLdZ8EjprkNQ4BLp/kNSRJkrQH7LavTEwVVfXwHljj7sleQ5IkSXvGTKwQS5IkSeNmQixJkqSBZkIsSZKkgTbjvjIxBfmAJUmSpoa+X5mYcS/VSdJke23Htr0dgibZ3Fn7jd1J0ozhlglJkiQNNBNiSZIkDTQTYkmSJA00E2JJkiQNNBNiSZIkDTQTYkmSJA00E2JJkiQNNBNiSZIkDbQJJ8RJDktya5Knkzya5KEk5+yO4PqsNTvJS0k+PUa/q5Oc0o7PSLI+yYYkDyY5trWf0trfSLJilLkWJ/lGkqeS/FaStPbPJDl9d96fJEmS9rwJJcQtObwDeKCqjqmqxcB5wJG7I7g+zgQ2Ax8YTkz7xHQwsLSqHmhNvwP8fFW9A7gV+FRrfw74UGsbze8AFwLHtb+fau3XAr/65m5DkiRJU8VEK8SnA9ur6vrhhqp6tqquBUgyK8lVSR5J8niSi1r78iT3J7ktyZNJbulUXhcn+VqrNq9JMr+z3krgGnrJ7NKdxLQCuKtzXsAB7fhA4Nstzi1V9TjwNzu7ubb2AVX1UFUV8LvA2cP3CcxL8tbxPChJkiRNTRNNiBcB60e5fgHwSlUtAZYAH0lydLt2IvAJ4O3AMcCyJHPoVV5XtGrzTcAVAEn2Bc4Avgx8gV5y3M8y4NHO+S8CX00yBJwP/PtduL8jgKHO+VBrG7a+rfd9klyYZF2SdatXr96F5SRJkrSnzd6dkyW5DjiZXtV4Cb0tDid09ugeSG/bwXZgbVUNtXEbgAXAVuB44O5WMJ4FPN/GngXcV1XbktwOXJ7kkqraMSKM+cCLnfNLgJ+pqoeT/Arwm/SS5HHdUp+26hy/ABz+Ax2qVgOr+/SXJEnSFDPRhHgTcO7wSVVdnOQQYF1rCvCxqlrTHZRkOfB6p2lHiyXApqo6qc9aK+lVkbe083nAacA9I/q9Csxt6xwK/FhVPdyufZHv304xliG+fz/0kbQtF83ctp4kSZKmqYlumbgXmJtkVadtv87xGmBV2wpBkoVJ9h9lvs3AoUlOav3nJFmU5AB6leejqmpBVS0ALqb/tokngGPb8XeBA5MsbOf/tF0fl6p6HvirJEvbHudfAO7sdFkIbBzvfJIkSZp6JpQQtxfNzgZOTfJMkrXAzcBlrcuNwDeB9Uk2AjcwSlW6qrbTeynuyiSPARuAdwPvA+6tqm5V+U7gvUn2GTHNV4Dlbb43gI8At7f5zgd+BSDJkrav+P3ADUk2DU/QtnAMW9Xu4yngfwB/0PrMoZd4r0OSJEnTVno57cyS5EHgrKraOolrnAP8eFVdPkbXmfeApQH32o5tezsETbK5s/Ybu5Ok6ajvZ3tn6i/VfRI4apLXmA38h0leQ5IkSZNsRlaIpxgfsDTDWCGe+awQSzPWQFWIJUmSpHExIZYkSdJAMyGWJEnSQDMhliRJ0kDzpbrJ5wOWJEmaGvq+VDfRn26W1PjlgcHg1wckaeZxy4QkSZIGmgmxJEmSBpoJsSRJkgaaCbEkSZIGmgmxJEmSBpoJsSRJkgaaCbEkSZIGmgmxJEmSBtqEEuIkhyW5NcnTSR5N8lCSc3ZXcCPWmp3kpSSfHqPf1UlOacenJ1mfZGOSm5PMbu1va7G+nuSXR5nr6CQPJ/lWki8meUtr/2iSD+/O+5MkSdLe8aYT4iQB7gAeqKpjqmoxcB5w5O4KboQzgc3AB9ra/WI6GFhaVQ8k+XvAzcB5VXU88Czwwdb1ZeDjwGfGWPNK4LNVdRzwXeCC1n5TGy9JkqRpbiIV4tOB7VV1/XBDVT1bVdcCJJmV5KokjyR5PMlFrX15kvuT3JbkySS3DCe4SRYn+VqrNq9JMr+z3krgGuA5YOlOYloB3NWO5wGvV9WftfO7gXNbnC9U1SPA93Z2cy2m04HbWtPNwNlt/DZgS5J37WTshUnWJVm3evXqnS0hSZKkKWD2BMYuAtaPcv0C4JWqWpJkH+DrSf6wXTuxjf828HVgWZKHgWuBn62qF5P8HHAF8M+S7AucAVwEHEQvOX6oz5rL+LsE9iVgTpJ3VtU6esnyD+/C/c0DtlbVG+18CDiic30d8B5g7ciBVbUaGM6EaxfWlCRJ0h42kYT4+yS5DjiZXtV4Cb0tDickWdG6HAgcB2wH1lbVUBu3AVgAbAWOB+5uBeNZwPNt7FnAfVW1LcntwOVJLqmqHSPCmA+8CFBVleQ84LMtIf9D4A3Gr9+2jG5y+wLwtl2YT5IkSVPQRBLiTbQtCABVdXGSQ+hVTqGXUH6sqtZ0ByVZDrzeadrR4giwqapO6rPWSnpV5C3tfB5wGnDPiH6vAnM7MT1Er4pLkjOBheO/PV4CDkoyu1WJj6RX0R42t60nSZKkaWwie4jvBeYmWdVp269zvAZYlWQOQJKFSfYfZb7NwKFJTmr95yRZlOQAepXno6pqQVUtAC6mlySP9ARw7PBJkn/Y/t0HuAy4vs+YvqqqgPvobbWA3gt5d3a6LAQ2jnc+SZIkTU1vOiFuCePZwKlJnkmylt6LZ5e1LjcC3wTWJ9kI3MAoFemq2k4v+bwyyWPABuDdwPuAe6uqW1W+E3hvS3S7vgIs75z/SpIngMeB/1ZV9wIkeWuSIeBS4FNJhlriTZKvJjm8jb8MuDTJU/Sq0p/rzL2MH6xQS5IkaZpJL6+dOZI8CJxVVVsncY0TgUur6vxxdJ9ZD1g79dqObXs7BO0Bc2ftN3YnSdJU1ffTvTPxl+o+CRw1yWscAlw+yWtIkiRpD5hxFeIpyAc8IKwQDwYrxJI0rQ1MhViSJEkaNxNiSZIkDTQTYkmSJA009xBPPh+wJEnS1NB3D/Fu++lmSRoUv/f0LXs7BE2y9x/z83s7BEl7kFsmJEmSNNBMiCVJkjTQTIglSZI00EyIJUmSNNBMiCVJkjTQTIglSZI00EyIJUmSNNBMiCVJkjTQxpUQJzksya1Jnk7yaJKHkpwzGQElmZ3kpSSfHqPf1UlOaccfTfJUkkpySKfPzyd5vP399yQ/1rl2U5IXkmwcZY0k+a029+NJfry1H5rkronfrSRJkva2MRPiJAHuAB6oqmOqajFwHnDkJMV0JrAZ+EBbu19MBwNLq+qB1vR14CeAZ0d0fQY4tapOAP4NsLpz7fPAT40Ry08Dx7W/C4HfAaiqF4Hnkywb5z1JkiRpihpPhfh0YHtVXT/cUFXPVtW1AElmJbkqySOtinpRa1+e5P4ktyV5MsktwwluksVJvtaqzWuSzO+stxK4BngOWLqTmFYAf1uhrao/raotIztV1X+vqu+20z+hk8S3ZPrlMe79Z4HfrZ4/AQ7qxHoH4G97SpIkTXPjSYgXAetHuX4B8EpVLQGWAB9JcnS7diLwCeDtwDHAsiRzgGuBFa3afBNwBUCSfYEzgC8DX6CXHPezDHh0HLGPjPMPdnHMEcCfd86HWhvAOuA9/QYluTDJuiTrVq9e3a+LJEmSpojZuzogyXXAyfSqxkvobXE4IcmK1uVAelsMtgNrq2qojdsALAC2AscDd7eC8Szg+Tb2LOC+qtqW5Hbg8iSXVNWOEWHMB17chZhPo5cQn7yrt9unrdq/LwCH9xtUVav5u+0Z1a+PJEmSpobxJMSbgHOHT6rq4vbi2rrWFOBjVbWmOyjJcuD1TtOOtl6ATVV1Up+1VtKrIm9p5/OA04B7RvR7FZg7jthJcgJwI/DTVfWd8YzpGAJ+uHN+JPDtdjy3xSFJkqRpbDxbJu4F5iZZ1Wnbr3O8BljVtkKQZGGS/UeZbzNwaJKTWv85SRYlOYBeBfeoqlpQVQuAi+m/beIJ4NixAk9yFPD7wPlV9Wdj9e/jS8AvtK9NLKW3NWS4mr0Q2OkXKiRJkjQ9jJkQV1UBZwOnJnkmyVrgZuCy1uVG4JvA+vYJsxsYpfJcVdvpvRR3ZZLHgA3Au4H3AfdWVbeqfCfw3iT7jJjmK8Dy4ZMkH08yRK+C+3iSG9ulX6NXZf7tJBuSrOuM+QLwEPAjSYaSXNDa/3mSf966fRV4GngK+I/AL3ViOK3FIUmSpGksvXx3+knyIHBWVW3dS+s/APxs5ysWOzM9H7Cknfq9p2/Z2yFokr3/GD8iJM1QfT/pO51/qe6TwFF7Y+EkhwK/OY5kWJIkSVPcLn9lYqqoqof34tov0vsOsSRJkqa56VwhliRJkibMhFiSJEkDzYRYkiRJA82EWJIkSQNt2n52bRrxAUuSJE0NfT+7Nm2/MjFd/Nkr/pjdIFh44PF7OwRJkvQmuWVCkiRJA82EWJIkSQPNhFiSJEkDzYRYkiRJA82EWJIkSQPNhFiSJEkDzYRYkiRJA82EWJIkSQNtXAlxksOS3Jrk6SSPJnkoyTmTEVCS2UleSvLpMfpdneSUdvzRJE8lqSSH9Om7JMmOJCs6bXcl2Zrky6OssU+SL7a5H06yoLX/aJLPv8lblCRJ0hQyZkKcJMAdwANVdUxVLQbOA46cpJjOBDYDH2hr94vpYGBpVT3Qmr4O/ATwbJ++s4ArgTUjLl0FnD9GLBcA362qY4HPtnmoqm8ARyY5alx3JEmSpClrPBXi04HtVXX9cENVPVtV10Iv4UxyVZJHkjye5KLWvjzJ/UluS/JkkluGE9wki5N8rVWb1ySZ31lvJXAN8BywdCcxrQDu6sTzp1W1ZSd9PwbcDrzQbayqPwL+aox7/1ng5nZ8G3BGJ0n/b/T+h8EPSHJhknVJ1n3x8783xhKSJEnam8aTEC8C1o9y/QLglapaAiwBPpLk6HbtROATwNuBY4BlSeYA1wIrWrX5JuAKgCT7AmcAXwa+QC857mcZ8OhYgSc5AjgHuH6svjtxBPDnAFX1BvAKMK9dWwe8p9+gqlpdVe+sqnf+3Ife/yaXliRJ0p4we1cHJLkOOJle1XgJvS0OJ3T25x4IHAdsB9ZW1VAbtwFYAGwFjgfubsXWWcDzbexZwH1VtS3J7cDlSS6pqh0jwpgPvDiOcK8GLquqHTvZfTHm7fZpq/bvC8Dhb2ZSSZIkTR3jSYg3AecOn1TVxe3FtXWtKcDHqur79ugmWQ683mna0dYLsKmqTuqz1kp6VeQt7XwecBpwz4h+rwJzxxH7O4H/2pLhQ4CfSfJGVd0xjrEAQ8APA0NJZtNL9l9u1+a2OCRJkjSNjWfLxL3A3CSrOm37dY7XAKvaVgiSLEyy/yjzbQYOTXJS6z8nyaIkB9CrPB9VVQuqagFwMf23TTwBHDtW4FV1dGeu24Bf2oVkGOBLwAfb8Qrg3qoarhAvBDbuwlySJEmagsZMiFsCeDZwapJnkqyl96LZZa3LjcA3gfVJNgI3MErluaq200sur0zyGLABeDfwPnoJZ7eqfCfw3iT7jJjmK8Dy4ZMkH08yRO/LF48nuXGs+0ryx8Dv0XtRbijJT7b230jy3tbtc8C8JE8BlwK/2pnitBaHJEmSprH8XcFzeknyIHBWVW3dC2vvA3wNOLm9bLdTf/bKxun5gLVLFh54/N4OQZIkja3vS2XT+ZfqPgnsre8AHwX86ljJsCRJkqa+Xf7KxFRRVQ/vxbW/BXxrb60vSZKk3Wc6V4glSZKkCTMhliRJ0kAzIZYkSdJAm7ZfmZhGfMCSJElTQ9+vTEzbl+qkqea1Hdv2dgjaA+bO2m/sTpKkacUtE5IkSRpoJsSSJEkaaCbEkiRJGmgmxJIkSRpoJsSSJEkaaCbEkiRJGmgmxJIkSRpoJsSSJEkaaONKiJMcluTWJE8neTTJQ0nOmYyAksxO8lKST4/R7+okp7TjjyZ5KkklOaTTZ3mSV5JsaH+/1rl2U5IXkmwcZY0k+a029+NJfry1H5rkronfrSRJkva2MRPiJAHuAB6oqmOqajFwHnDkJMV0JrAZ+EBbu19MBwNLq+qB1vR14CeAZ/t0/+Oqekf7+41O++eBnxojlp8Gjmt/FwK/A1BVLwLPJ1k2vluSJEnSVDWeCvHpwPaqun64oaqeraprAZLMSnJVkkdaFfWi1r48yf1JbkvyZJJbhhPcJIuTfK1Vm9ckmd9ZbyVwDfAcsHQnMa0A/rZCW1V/WlVbduG+acn0y2N0+1ngd6vnT4CDOrHeAfz8rqwpSZKkqWc8CfEiYP0o1y8AXqmqJcAS4CNJjm7XTgQ+AbwdOAZYlmQOcC2wolWbbwKuAEiyL3AG8GXgC/SS436WAY+OI3aAk5I8luQPkiwa55hhRwB/3jkfam0A64D39BuU5MIk65KsW7169S4uKUmSpD1p9q4OSHIdcDK9qvESelscTkiyonU5kN4Wg+3A2qoaauM2AAuArcDxwN2tYDwLeL6NPQu4r6q2JbkduDzJJVW1Y0QY84EXxxHueuAfVdVfJ/kZelXd43bldvu0Vfv3BeDwfoOqajWwekR/SZIkTUHjSYg3AecOn1TVxe3FtXWtKcDHqmpNd1CS5cDrnaYdbb0Am6rqpD5rraRXRd7SzucBpwH3jOj3KjB3rMCr6i87x19N8ttJDqmql8Ya2wwBP9w5PxL4djue2+KQJEnSNDaeLRP3AnOTrOq07dc5XgOsalshSLIwyf6jzLcZODTJSa3/nCSLkhxAr/J8VFUtqKoFwMX03zbxBHDsWIEneWtn3/K76N3vd8Ya1/El4Bfa1yaW0tsaMlzNXgjs9AsVkiRJmh7GTIirqoCzgVOTPJNkLXAzcFnrciPwTWB9+4TZDYxSea6q7fReirsyyWPABuDdwPuAe6uqW1W+E3hvkn1GTPMVYPnwSZKPJxn6/9u7/2i7yvre9+/PDT8iVqEC5UQiDTkQWkJRimkJAQnizzE4/ChpDxxutS1XBFGLUC9ah6O2Do6ltKJSqu5SDugFjxesiGLJofyKcsEQQhIIPxSD6D5SARWqguQYv/eP9Wxd7LOz99oh2Xsv1vs1xh6Z85nPM5/vXHPs8OWbZ85Fp4K7LsnF7dAy4J42z8eAE9v1kOQzwG3AfkmGk5zS2k9Lclob/2VgA/Ag8I/A27piOLLFIUmSpD6Wlh/2nSRfBY6uqiemaf4VwLFV9cMJuvbnB6xJ++mmp6Y7BE2B2bN2mriTJGmmGvOVvv38TXVnA3tNx8RJdgc+3EMyLEmSpBmubyvEfcQPeEBYIR4MVoglqa897yrEkiRJ0nNmQixJkqSBZkIsSZKkgeYa4m3PD1iSJGlmcA2xJEmSNFovX90sqQe+ZWIw+JYJSXr+sUIsSZKkgWZCLEmSpIFmQixJkqSBZkIsSZKkgWZCLEmSpIFmQixJkqSBZkIsSZKkgdZTQpxkjyRXJNmQ5M4ktyU5flsElGS7JI8n+dAE/T6S5FVt++1JHkxSSXYb1W9pkjVJ1ie5pav9kiSPJrlnnDmS5GPt3OuS/HZr3z3Jdc/tSiVJkjQTTJgQJwlwNbCiquZX1cHAicDcbRTT64AHgD9oc48V00uAQ6pqRWu6FXgN8PCofrsA/wAcU1ULgd/vOnwp8IYJYnkjsG/7ORX4OEBVPQY8kmRJ75clSZKkmaiXCvGrgY1V9YmRhqp6uKouBEgyK8n5Se5oVdS3tvalSW5OclWS+5NcPpLgJjk4yS2t2rw8yZyu+U4CPgp8GzhkMzEtA35Roa2qu6rqW2P0+y/AP1fVt1u/R7vGrAB+MMG1Hwt8qjpuB3bpivVq4OQJxkuSJGmG6yUhXgisHuf4KcCTVbUIWAS8Jcne7dhBwJnA/sB8YEmS7YELgWWt2nwJcC5AkhcARwFfAj5DJzkeyxLgzh5iXwD8akvM70zyph7GdNsT+E7X/nBrA1gFHD7WoCSnJlmVZNXQ0NAkp5QkSdJU2m6yA5JcBBxGp2q8iM4ShwOTLGtddqazxGAjsLKqhtu4NcA84AngAOD6VjCeBTzSxh4N3FRVTyX5HPD+JO+qqk2jwpgDPNbj9R1MJ8l+AXBbktur6uu9Xu4YbdX+fBR46ViDqmoIGBrVX5IkSTNQLwnxeuCEkZ2qOqM9uLaqNQV4R1Ut7x6UZCnwTFfTpjZfgPVVtXiMuU6iU0X+VtvfFTgS+NdR/Z4GZvcQ+zDweFX9BPhJkhXAy4FeE+Jh4GVd+3OB77bt2S0OSZIk9bFelkzcCMxOcnpX205d28uB09tSCJIsSPLCcc73ALB7ksWt//ZJFiZ5MZ3K815VNa+q5gFnMPayifuAfXqI/QvA4e3NFTsBv9vG9uoa4E3tbROH0FkaMlLNXgBs9g0VkiRJ6g8TJsRVVcBxwBFJHkqyErgMOKd1uRi4F1jdXmH2ScapPFfVRjoPxZ2XZC2wBjgU+D3gxqrqrip/ATgmyY6jTnMtsHRkJ8k7kwzTqeCuS3Jxm+s+Og/frQNWAhdX1T1tzGeA24D9kgwnOaW1n5bktHbqLwMbgAeBfwTe1hXDkS0OSZIk9bF08t3+k+SrwNFV9cQ0zb8COLaqfjhB1/78gDVpP9301HSHoCkwe9ZOE3eSJM1UY77St5+/qe5sYK/pmDjJ7sCHe0iGJUmSNMP1bYW4j/gBDwgrxIPBCrEk9bXnXYVYkiRJes5MiCVJkjTQTIglSZI00EyIJUmSNNB8qG7b8wOWJEmaGcZ8qK6Xr26WJGkg+faY5z/fHCNwyYQkSZIGnAmxJEmSBpoJsSRJkgaaCbEkSZIGmgmxJEmSBpoJsSRJkgaaCbEkSZIGmgmxJEmSBlpPCXGSPZJckWRDkjuT3Jbk+G0RUJLtkjye5EMT9PtIkle17bcneTBJJdmtq8+7k6xpP/ck2ZTkJe3YJUkeTXLPOHMkycfaudcl+e3WvnuS67bOFUuSJGk6TZgQJwlwNbCiquZX1cHAicDcbRTT64AHgD9oc48V00uAQ6pqRWu6FXgN8HB3v6o6v6peUVWvAN4L3FJVP2iHLwXeMEEsbwT2bT+nAh9v530MeCTJkklemyRJkmaYXirErwY2VtUnRhqq6uGquhAgyawk5ye5o1VR39ralya5OclVSe5PcvlIgpvk4CS3tGrz8iRzuuY7Cfgo8G3gkM3EtAz4RYW2qu6qqm9NcB0nAZ/pGrMC+MHmuwNwLPCp6rgd2KUr1quBkycYL0mSpBmul4R4IbB6nOOnAE9W1SJgEfCWJHu3YwcBZwL7A/OBJUm2By4ElrVq8yXAuQBJXgAcBXyJTvJ60mbmXALc2UPstPPuRKca/LlexzR7At/p2h9ubQCrgMM3M9+pSVYlWTU0NDTJKSVJkjSVtpvsgCQXAYfRqRovorPE4cAky1qXneksMdgIrKyq4TZuDTAPeAI4ALi+FYxnAY+0sUcDN1XVU0k+B7w/ybuqatOoMOYAj00i7P8E3Nq1XKJXYy3ZqPbno8BLxxpUVUPA0Kj+kiRJmoF6SYjXAyeM7FTVGe3BtVWtKcA7qmp596AkS4Fnupo2tfkCrK+qxWPMdRKdKvK32v6uwJHAv47q9zQwu4fYR5xI13KJSRgGXta1Pxf4btue3eKQJElSH+tlycSNwOwkp3e17dS1vRw4vS2FIMmCJC8c53wPALsnWdz6b59kYZIX06k871VV86pqHnAGYy+buA/Yp4fYSbIzcATwhV76j3IN8Kb2tolD6CwNGalmLwA2+4YKSZIk9YcJE+KqKuA44IgkDyVZCVwGnNO6XAzcC6xurzD7JONUnqtqI52H4s5LshZYAxwK/B5wY1V1V5W/AByTZMdRp7kWWDqyk+SdSYbpVHDXJbm4q+/xwP+oqp90nyDJZ4DbgP2SDCc5pbWfluS01u3LwAbgQeAfgbd1neLIFockSZL6WDr5bv9J8lXg6Kp6YprmXwEcW1U/nKBrf37AkiR+uump6Q5B29jsWTtN3EnPJ2O+0refv6nubGCv6Zg4ye7Ah3tIhiVJkjTD9W2FuI/4AUtSn7JC/PxnhXjgPO8qxJIkSdJzZkIsSZKkgWZCLEmSpIHmGuJtzw9YkiRpZnANsSRJkjRaL1/dLKkHPo0+GHwiXZKef6wQS5IkaaCZEEuSJGmgmRBLkiRpoJkQS5IkaaCZEEuSJGmgmRBLkiRpoJkQS5IkaaD1lBAn2SPJFUk2JLkzyW1Jjt8WASXZLsnjST40Qb+PJHlV2357kgeTVJLduvr8apLPJ1mXZGWSA7qOXZLk0ST3jDNHknysnXtdkt9u7bsnue65X60kSZKm24QJcZIAVwMrqmp+VR0MnAjM3UYxvQ54APiDNvdYMb0EOKSqVrSmW4HXAA+P6vrnwJqqOhB4E/DRrmOXAm+YIJY3Avu2n1OBjwNU1WPAI0mW9HhNkiRJmqF6qRC/GthYVZ8Yaaiqh6vqQoAks5Kcn+SOVkV9a2tfmuTmJFcluT/J5SMJbpKDk9zSqs3Lk8zpmu8kOonrt4FDNhPTMuAXFdqququqvjVGv/2BG1qf+4F5SfZo+yuAH0xw7ccCn6qO24FdumK9Gjh5gvGSJEma4XpJiBcCq8c5fgrwZFUtAhYBb0mydzt2EHAmncR0PrAkyfbAhcCyVm2+BDgXIMkLgKOALwGfoZMcj2UJcGcPsa8Ffq+d+3eAX2dyle09ge907Q+3NoBVwOFjDUpyapJVSVYNDQ1NYjpJkiRNte0mOyDJRcBhdKrGi+gscTgwybLWZWc6Sww2AiurariNWwPMA54ADgCubwXjWcAjbezRwE1V9VSSzwHvT/Kuqto0Kow5wGM9hPvXwEfb3HcDdwE/m8zljtFW7c9HgZeONaiqhoChUf0lSZI0A/WSEK8HThjZqaoz2oNrq1pTgHdU1fLuQUmWAs90NW1q8wVYX1WLx5jrJDpV5G+1/V2BI4F/HdXvaWD2RIFX1b8Df9ziCfBQ++nVMPCyrv25wHfb9uwWhyRJkvpYL0smbgRmc3Zh3gAAGvJJREFUJzm9q22nru3lwOltKQRJFiR54TjnewDYPcni1n/7JAuTvJhO5XmvqppXVfOAMxh72cR9wD4TBZ5klyQ7tN3/i86Dgf8+0bgu1wBvam+bOITO0pCRavYCYLNvqJAkSVJ/mDAhrqoCjgOOSPJQkpXAZcA5rcvFwL3A6vYKs08yTuW5qjbSeSjuvCRrgTXAoXTW+t5YVd1V5S8AxyTZcdRprgWWjuwkeWeSYToV3HVJLm6HfhNYn+R+Om+M+NOuMZ8BbgP2SzKc5JTWflqS01q3LwMbgAeBfwTe1hXDkS0OSZIk9bF08t3+k+SrwNFV9cQ0zb8COLaqfjhB1/78gDVpP9301HSHoCkwe9ZOE3eSJM1UY77St5+/qe5sYK/pmDjJ7sCHe0iGJUmSNMP1bYW4j/gBDwgrxIPBCrEk9bXnXYVYkiRJes5MiCVJkjTQTIglSZI00EyIJUmSNNB8qG7b8wOWJEmaGcZ8qK6Xr26WJEl6XnvnLWdPdwjaxj52xN9t9phLJiRJkjTQTIglSZI00EyIJUmSNNBMiCVJkjTQTIglSZI00EyIJUmSNNBMiCVJkjTQTIglSZI00HpKiJPskeSKJBuS3JnktiTHb4uAkvxZkvuT3JNkbZI3babfR5K8alTbhUl+3LV/VpJ7k6xLckOSX+86dl2SJ5J8aZxYdkzy2SQPJvlaknmt/beSXPocL1WSJEkzwIQJcZIAVwMrqmp+VR0MnAjM3drBJDkNeC3wO1V1APAqxviKvSQvAQ6pqhVdba8EdhnV9S7glVV1IHAV8Dddx84H/nCCkE4BflhV+wAXAOcBVNXdwNwke03i8iRJkjQD9VIhfjWwsao+MdJQVQ9X1YUASWYlOT/JHa0S+9bWvjTJzUmuahXfy1tyTZKDk9zSqs3Lk8xpp/5z4G1V9e9tnier6rIxYloGXDeyk2QWnQT3/+7uVFU3VdVTbfd2upL4qroB+NEE134sMDL/VcBRI9cAfJHO/xhIkiSpj/WSEC8EVo9z/BTgyapaBCwC3pJk73bsIOBMYH9gPrAkyfbAhcCyVm2+BDg3yYuAF1XVN3uIaQlwZ9f+24FrquqRCeL8lx7O3W1P4DsAVfUz4Elg13ZsFXD4WIOSnJpkVZJVQ0NDk5xSkiRJU2m7yQ5IchFwGJ2q8SLgdcCBSZa1LjsD+wIbgZVVNdzGrQHmAU8ABwDXt2LrLOAROksjqscw5gCPtfO+FPh9YOk4Mf+fwCuBI3o8/y+GjtE2EuOjwEvHGlRVQ8DQqP6SJEmagXpJiNcDJ4zsVNUZSXajUyGFTtL4jqpa3j0oyVLgma6mTW2+AOuravHoiZL8JMn8qtowQUxPA7Pb9kHAPsCDLcHeKcmDbd0vSV4DvA84oqqeGetk4xgGXgYMJ9mOTrL/g3ZsdotDkiRJfayXJRM3ArOTnN7VtlPX9nLg9LYUgiQLkrxwnPM9AOyeZHHrv32She3Yh4CLkry4HXtxklPHOMd9dJJgquraqvoPVTWvquYBT3UlwwcBnwSOqapHe7jW0a4B3ty2lwE3VtVIxXcBcM8WnFOSJEkzyIQJcUsAjwOOSPJQkpV0HjQ7p3W5GLgXWJ3kHjoJ6GYrz1W1kU5yeV6StcAa4NB2+OPATcAd7Vy3AE+NcZprGWeJRJfzgV8BrkyyJsk1IweSfAW4ks6DcsNJXt/a/yrJMa3bPwG7JnkQOAt4T9e5j2xxSJIkqY/llwXP/pLkq8DRVfXENMy9I51k/bD2sN14+vMDliRpgLzzlrOnOwRtYx874u9g7OfD+vqb6s4Gpus9wHsB7+khGZYkSdIMN+m3TMwUVfW1aZz7G8A3pmt+SZIkbT39XCGWJEmSnjMTYkmSJA00E2JJkiQNtL59y0Qf8QOWJEmaGZ53b5mQJEmSnrO+fctEv7jtezdPdwiaAov3WDrdIUiSpC1khViSJEkDzYRYkiRJA82EWJIkSQPNhFiSJEkDzYRYkiRJA82EWJIkSQPNhFiSJEkDbcKEOMkeSa5IsiHJnUluS3L81g4kyaVJHkqyNsnXk3wqyZ7j9L8qyfy2vUOSoTbu/iQnjOq7LEkleWXb3zXJTUl+nOTvx5njJUmuT/KN9uevtvajk/zl1rlySZIkTadxE+IkAa4GVlTV/Ko6GDgRmLuN4nl3Vb0c2A+4C7gpyQ5jxLUQmFVVG1rT+4BHq2oBsD9wS1ffFwHvBL7WdYqfAu8H/myCeN4D3FBV+wI3tH2Aa4Fjkuw0yeuTJEnSDDNRhfjVwMaq+sRIQ1U9XFUXAiSZleT8JHckWZfkra19aZKbWxX3/iSXt+SaJAcnuaVVm5cnmTN60uq4APg34I1jxHUy8IWu/T8BPtTG/ryqHu869kHgb+gkwSPn/0lVfbW7bTOOBS5r25cBx43EB9wMHD3BeEmSJM1wEyXEC4HV4xw/BXiyqhYBi4C3JNm7HTsIOJNOxXY+sCTJ9sCFwLJWbb4EOHec868GfmOM9iXAnQBJdmltH0yyOsmVSfZoxw4CXlZVX5rgOjdnj6p6BKD9+Wtdx1YBh481KMmpSVYlWXX1p7+4hVNLkiRpKmw3mc5JLgIOo1M1XgS8DjgwybLWZWdgX2AjsLKqhtu4NcA84AngAOD6VjCeBTwy3pSbaZ8DPNZ1DXOBW6vqrCRnAX+b5M3ABcAfTeYaJ+FR4KVjHaiqIWAI4Lbv3VzbaH5JkiRtBRMlxOuBXzygVlVnJNmNTnUUOgnrO6pqefegJEuBZ7qaNrW5AqyvqsU9xncQnbW7oz0NzG7b3weeAj7f9q+kU7l+EZ3k++aWfP8H4Jokx1TVKnrzvSRzquqRtrTj0a5js1sckiRJ6mMTLZm4EZid5PSutu4HyZYDp7elECRZkOSF45zvAWD3JItb/+3bA3LPko530qkEXzfGee4D9oFfrOf9IrC0HTsKuLeqnqyq3apqXlXNA24HJpMMA1wDvLltv5lnr1teANwziXNJkiRpBho3IW7J5nHAEe2VaCvpPFx2TutyMXAvsDrJPcAnGafqXFUbgWXAeUnWAmuAQ7u6nN/av05nTfKRbcxo1/LLBJgWzweSrAP+EDh7vOsCSPIt4MPAHyUZTrJ/a7945PVswF8Dr03yDeC1bX/EkS0OSZIk9bF0ct7+kuQFwE3AkqraNA3z7wFcUVVHTdTXNcSDYfEeS6c7BEmSNLExn0/ry2+qq6qngb8ANvvFHdvYXvRQhZYkSdLMN6m3TMwkox/km+K575iuuSVJkrR19WWFWJIkSdpaTIglSZI00EyIJUmSNNBMiCVJkjTQ+vK1a33GD1iSJGlmGPO1a337lglJmi5Xbrh8ukPQNvb780+e7hAkTSGXTEiSJGmgmRBLkiRpoJkQS5IkaaCZEEuSJGmgmRBLkiRpoJkQS5IkaaCZEEuSJGmgmRBLkiRpoE2YECfZI8kVSTYkuTPJbUmO39qBJLk0yUNJ1ib5epJPJdlznP5XJZnftndIMtTG3Z/khK5+f5Dk3iTrk1zR1X5dkieSfGmcOXZM8tkkDyb5WpJ5rf23kly6FS5bkiRJ02zchDhJgKuBFVU1v6oOBk4E5m6jeN5dVS8H9gPuAm5KssMYcS0EZlXVhtb0PuDRqloA7A/c0vrtC7wXWFJVC4Ezu05zPvCHE8RzCvDDqtoHuAA4D6Cq7gbmJtlryy5TkiRJM8VEFeJXAxur6hMjDVX1cFVdCJBkVpLzk9yRZF2St7b2pUlublXc+5Nc3pJrkhyc5JZWbV6eZM7oSavjAuDfgDeOEdfJwBe69v8E+FAb+/Oqery1vwW4qKp+2I492jXHDcCPJrj+Y4HL2vZVwFEj1wF8kc7/HEiSJKmPTZQQLwRWj3P8FODJqloELALekmTvduwgOhXZ/YH5wJIk2wMXAstatfkS4Nxxzr8a+I0x2pcAdwIk2aW1fTDJ6iRXJtmjtS0AFiS5NcntSd4wwfWOtifwHYCq+hnwJLBrO7YKOHysQUlOTbIqyaqhoaFJTilJkqSptN1kOie5CDiMTtV4EfA64MAky1qXnYF9gY3AyqoabuPWAPOAJ4ADgOtboXUW8Mh4U26mfQ7wWNc1zAVuraqzkpwF/C2d5RDbtXiWtj5fSXJAVT3R6yWP0Vbtz0eBl441qKqGgKFR/SVJkjQDTZQQrwd+8YBaVZ2RZDc61VHoJIzvqKrl3YOSLAWe6Wra1OYKsL6qFvcY30HADWO0Pw3MbtvfB54CPt/2r6RTuQYYBm6vqv8FPJTkAToJ8h09zj8MvAwYTrIdnYT/B+3Y7BaHJEmS+thESyZuBGYnOb2rbaeu7eXA6W0pBEkWJHnhOOd7ANg9yeLWf/v2gNyzpOOddCrB141xnvuAfaCz3pjOet6l7dhRwL1t+2rgyHbO3egsodhA764B3ty2lwE3tvlo57pnEueSJEnSDDRuQtySv+OAI9or0VbSecjsnNblYjrJ5+ok9wCfZJyqc1VtpJNYnpdkLbAGOLSry/mt/et01iQf2caMdi2/TIBp8XwgyTo6SyXObu3Lge8nuRe4ic5bLL4PkOQrdKrJRyUZTvL61v5XSY5p4/8J2DXJg8BZwHu65jyyxSFJkqQ+ll8WPPtHkhfQSXCXVNWmaZh/RzqvdjusPWw3nv77gCWN68oNl093CNrGfn/+ydMdgqRtY8zn0/rym+qq6mngL+i8BWI67AW8p4dkWJIkSTPcpN4yMZOMfpBviuf+BvCN6ZpfkiRJW09fVoglSZKkrcWEWJIkSQPNhFiSJEkDrS/fMtFn/IAlSZJmhufPWyYkSZKkraVv3zIhSdK2ltfOne4QtI3V9cPTHYJmACvEkiRJGmgmxJIkSRpoJsSSJEkaaCbEkiRJGmgmxJIkSRpoJsSSJEkaaCbEkiRJGmgTJsRJ9khyRZINSe5McluS47d2IEkuTfJQkrVJvp7kU0n2HKf/VUnmt+0dkgy1cfcnOaG1X5BkTfv5epInusZfl+SJJF8aZ44dk3w2yYNJvpZkXmv/rSSXbqVLlyRJ0jQaNyFOEuBqYEVVza+qg4ETgW31pvJ3V9XLgf2Au4CbkuwwRlwLgVlVtaE1vQ94tKoWAPsDtwBU1buq6hVV9QrgQuCfu05zPvCHE8RzCvDDqtoHuAA4r533bmBukr228DolSZI0Q0xUIX41sLGqPjHSUFUPV9WFAElmJTk/yR1J1iV5a2tfmuTmVsW9P8nlLbkmycFJbmnV5uVJ5oyetDouAP4NeOMYcZ0MfKFr/0+AD7WxP6+qx8cYcxLwma45bgB+NMH1Hwtc1ravAo4auQ7gi3T+50CSJEl9bKKEeCGwepzjpwBPVtUiYBHwliR7t2MHAWfSqdjOB5Yk2Z5OpXZZqzZfApw7zvlXA78xRvsS4E6AJLu0tg8mWZ3kyiR7dHdO8uvA3sCN48w1lj2B7wBU1c+AJ4Fd27FVwOFjDUpyapJVSVYNDQ1NckpJkiRNpe0m0znJRcBhdKrGi4DXAQcmWda67AzsC2wEVlbVcBu3BpgHPAEcAFzfCq2zgEfGm3Iz7XOAx7quYS5wa1WdleQs4G959nKIE4GrqmpT71e72fmr/fko8NKxBlXVEDA0qr8kSZJmoIkS4vXACSM7VXVGkt3oVEehkzC+o6qWdw9KshR4pqtpU5srwPqqWtxjfAcBN4zR/jQwu21/H3gK+Hzbv5JO5brbicAZPc7ZbRh4GTCcZDs6Cf8P2rHZLQ5JkiT1sYmWTNwIzE5yelfbTl3by4HT21IIkixI8sJxzvcAsHuSxa3/9u0BuWdJxzvpVIKvG+M89wH7QGe9MZ31vEvbsaOAe7vOtR/wq8Bt48S1OdcAb27by4Ab23wAC4B7tuCckiRJmkHGTYhb8ncccER7JdpKOg+ZndO6XEwn+Vyd5B7gk4xTda6qjXQSy/OSrAXWAId2dTm/tX+dzprkI9uY0a7llwkwLZ4PJFlHZ6nE2V3HTgL+e1ciC0CSr9CpJh+VZDjJ61v7XyU5pnX7J2DXJA8CZwHv6TrFkS0OSZIk9bGMyhP7QpIXADcBS7ZgXfDWmH9HOq92O6w9bDee/vuAJUkA5LXb6i2jminq+uHpDkFTa8zn0/rym+qq6mngL+i8BWI67AW8p4dkWJIkSTPcpN4yMZOMfpBviuf+BvCN6ZpfkiRJW09fVoglSZKkrcWEWJIkSQPNhFiSJEkDzYRYkiRJA60vX7vWZ/yAJUmSZoYxX7vWt2+ZkGaaPc9dOt0haAr8z/fdPN0hSJK2MpdMSJIkaaCZEEuSJGmgmRBLkiRpoJkQS5IkaaCZEEuSJGmgmRBLkiRpoJkQS5IkaaCZEEuSJGmg9ZwQJ9kjyRVJNiS5M8ltSY7f2gEluTTJQ0nWtJ//bzP9DkpycdveOckXk6xNsj7JH3f1+5vWdl+SjyVJaz83yXeS/HiCeN6b5MEkDyR5fWvbIcmKJH6xiSRJUp/rKSFuSeTVwIqqml9VBwMnAnO3UVzvrqpXtJ9DN9Pnz4EL2/YZwL1V9XJgKfB3LWk9FFgCHAgcACwCjmhjvgj8znhBJNmfznUuBN4A/EOSWVW1EbgB+M9beoGSJEmaGXqtEL8a2FhVnxhpqKqHq+pCgCSzkpyf5I4k65K8tbUvTXJzkquS3J/k8q4K7cFJbmnV5uVJ5vQadJIXAQdW1dqRcIAXtXP/CvAD4GetfTawA7AjsD3wvRb/7VX1yARTHQv896p6pqoeAh7kl0n01cDJvcYsSZKkmanXhHghsHqc46cAT1bVIjpV2Lck2bsdOwg4E9gfmA8sSbI9neruslZtvgQ4t+t853ctmbh8jPleCdzTtf/3wG8C3wXuBv60qn5eVbcBNwGPtJ/lVXVfj9cMsCfwna794dZGm3/RWIOSnJpkVZJVQ0NDk5hOkiRJU22L1sAmuQg4jE7VeBHwOuDAJMtal52BfYGNwMqqGm7j1gDzgCfoLGG4vhWMZ9FJWEe8u6quGieEOcBjXfuvB9bQqWT/x3berwC/RidRHlnacX2SV1XVil4vdYy2AqiqTUk2JnlRVf3oWR2qhoCh7v6SJEmamXpNiNcDJ4zsVNUZSXYDVrWmAO+oquXdg5IsBZ7patrU5gywvqoWb2HcT9NZCjHij4G/rqoCHkzyEPAbdNYL315VP27x/AtwCNBrQjwMvKxrfy6dKvSIHYGfbtEVSJIkaUbodcnEjcDsJKd3te3Utb0cOL0thSDJgiQvHOd8DwC7J1nc+m+fZOEk4r4P2Kdr/9vAUe1cewD7ARta+xFJtmuxHdHG9uoa4MQkO7YlIPsCK9s8uwKPVdX/msT5JEmSNMP0lBC3yutxdJLLh5KsBC4DzmldLgbuBVYnuQf4JONUn9tbGpYB5yVZS2e5Q/fbJLrXEK9JssOo8fcDO7eH6wA+CBya5G46b384p6oeB64CvklnXfFaYG1VfRF+8Tq2YWCnJMNJPtDaj0nyV22e9cD/267tOuCMqtrU5jwS+HIvn58kSZJmrnRy3f6T5F3Aj6rq4mma/5+B91bVAxN07c8PWJO257lLpzsETYH/+b6bpzsESdKWG+v5sL7+prqP8+z1yVOmVayv7iEZliRJ0gzXt9+0VlU/BT49TXNvBD41HXNLkiRp6+rnCrEkSZL0nJkQS5IkaaCZEEuSJGmg9e1bJvqIH7AkSdLMMOZbJvr2obo+MuYH/3yW5NT29dV6nvNeDw7v9WDwPg8O7/WzuWRC28Kp0x2Apoz3enB4rweD93lweK+7mBBLkiRpoJkQS5IkaaCZEGtbcE3S4PBeDw7v9WDwPg8O73UX3zIhSZKkgWaFWJIkSQPNhFj/myTvS7I+yboka5L8bpIzk+y0Bef68QTHd01yU5IfJ/n7LY9aW2KK7/Vrk9yZ5O7256u3PHJN1hTf699pc6xJsjbJ8VseuSZrKu91V7+92t/jfzb5iLUlpvh3el6Sp7t+rz+x5ZHPTL6HWM+SZDFwNPDbVfVMkt2AHYDPAv8P8NRWnvKnwPuBA9qPpsg03OvHgf9UVd9NcgCwHNhzK8+hMUzDvb4HeGVV/SzJHGBtki9W1c+28jwaZRru9YgLgH/ZRufWKNN0n79ZVa/YBuedEawQa7Q5wONV9QxAVT0OLANeCtyU5CZ49v9NJlmW5NK2vXeS25LckeSDXX0+neTYrv3LkxxTVT+pqq/SSYw1tab6Xt9VVd9tzeuB2Ul23MbXqI6pvtdPdSW/s/EbO6fSlN7rtn0csIHO77WmxpTf5+c7E2KN9j+AlyX5epJ/SHJEVX0M+C5wZFUdOcH4jwIfr6pFwL91tV8M/DFAkp2BQ4Evb/3wNQnTea9PAO4a+ctc29yU3+v2z7frgbuB06wOT5kpvddJXgicA/zl1r4QjWs6/v7eO8ldSW5JcvhWvZoZwIRYz1JVPwYOpvMNNo8Bn03yR5M4xRLgM237013nvQXYJ8mvAScBn/M/kNNruu51koXAecBbn9MFqGfTca+r6mtVtRBYBLw3yeznfCGa0DTc678ELmjzaopMw31+BNirqg4CzgKuSPLi53whM4hriPW/qapNwM3AzUnuBt48Vreu7dH/odvcP49+GjgZOBH4k+cYpraCqb7XSeYCnwfeVFXf3MKwtQWm6/e6qu5L8hM6zwismmTY2gJTfK9/F1iW5G+AXYCfJ/lpVfmQ9DY2lfe5/WveyPKMO5N8E1jA8+h32gqxniXJfkn27Wp6BfAw8CPgRV3t30vym0n+D6D7CfJb6fwSQecXqtulwJkAVeVas2k21fc6yS7AtcB7q+rWrXUdmtg03Ou9k2zXtn8d2A/41la5GI1rqu91VR1eVfOqah7wEeC/mgxve9PwO717klltez6wL511488bJsQa7VeAy5Lcm2QdsD/wATrfaPMvIwv1gfcAXwJupPNPKSP+FDgjyR3Azt0nrqrvAfcB/627Pcm3gA8Df5RkOMn+W/uiNKapvtdvB/YB3p9fvrrn17b+ZWkMU32vD6PzZok1dP5F4G3toR9te1P+d7imxVTf51cB65KsBa6i81zAD7b6VU0jv6lOUyaddyPeTec1MU9OdzzadrzXg8N7PTi814NhUO+zFWJNiSSvAe4HLhykX7BB5L0eHN7rweG9HgyDfJ+tEEuSJGmgWSGWJEnSQDMhliRJ0kAzIZYkSdJAMyGWJEnSQDMhliRJ0kAzIZYkSdJA+/8BdWxNhup3Pz4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 792x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4193952083587646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/storage2/wouter/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>SNP</th>\n",
       "      <th>importance_Study1</th>\n",
       "      <th>importance_Study2</th>\n",
       "      <th>importance_Study3</th>\n",
       "      <th>importance_Study4</th>\n",
       "      <th>importance_Study5</th>\n",
       "      <th>feature_genes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_141.0</td>\n",
       "      <td>0.164788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_71.0</td>\n",
       "      <td>0.167534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_1.0</td>\n",
       "      <td>0.086253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneD_641.0</td>\n",
       "      <td>0.236366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_151.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_161.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_191.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004623</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_91.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneE_881.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_121.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.319948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneD_661.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.321623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_171.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_51.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneD_671.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.924870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneC_421.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.481117</td>\n",
       "      <td>GeneC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   importance          SNP  importance_Study1  importance_Study2  \\\n",
       "0         NaN  GeneA_141.0           0.164788                NaN   \n",
       "1         NaN   GeneA_71.0           0.167534                NaN   \n",
       "2         NaN    GeneA_1.0           0.086253                NaN   \n",
       "3         NaN  GeneD_641.0           0.236366                NaN   \n",
       "4         NaN  GeneA_151.0                NaN           0.004507   \n",
       "5         NaN  GeneA_161.0                NaN           0.004535   \n",
       "6         NaN  GeneA_191.0                NaN           0.004564   \n",
       "7         NaN   GeneA_21.0                NaN           0.004593   \n",
       "8         NaN   GeneA_41.0                NaN           0.004623   \n",
       "9         NaN   GeneA_91.0                NaN           0.004653   \n",
       "10        NaN  GeneE_881.0                NaN           0.722596   \n",
       "11        NaN  GeneA_121.0                NaN                NaN   \n",
       "12        NaN   GeneA_11.0                NaN                NaN   \n",
       "13        NaN   GeneA_81.0                NaN                NaN   \n",
       "14        NaN  GeneD_661.0                NaN                NaN   \n",
       "15        NaN  GeneA_171.0                NaN                NaN   \n",
       "16        NaN   GeneA_51.0                NaN                NaN   \n",
       "17        NaN   GeneA_61.0                NaN                NaN   \n",
       "18        NaN  GeneD_671.0                NaN                NaN   \n",
       "19        NaN  GeneC_421.0                NaN                NaN   \n",
       "\n",
       "    importance_Study3  importance_Study4  importance_Study5 feature_genes  \n",
       "0                 NaN                NaN                NaN         GeneA  \n",
       "1                 NaN                NaN                NaN         GeneA  \n",
       "2                 NaN                NaN                NaN         GeneA  \n",
       "3                 NaN                NaN                NaN         GeneD  \n",
       "4                 NaN                NaN                NaN         GeneA  \n",
       "5                 NaN                NaN                NaN         GeneA  \n",
       "6                 NaN                NaN                NaN         GeneA  \n",
       "7                 NaN                NaN                NaN         GeneA  \n",
       "8            0.001592                NaN                NaN         GeneA  \n",
       "9                 NaN                NaN                NaN         GeneA  \n",
       "10                NaN                NaN                NaN         GeneE  \n",
       "11           0.319948                NaN                NaN         GeneA  \n",
       "12           0.001583                NaN                NaN         GeneA  \n",
       "13           0.001601                NaN                NaN         GeneA  \n",
       "14           0.321623                NaN                NaN         GeneD  \n",
       "15                NaN           0.004577                NaN         GeneA  \n",
       "16                NaN           0.004604                NaN         GeneA  \n",
       "17                NaN           0.004632                NaN         GeneA  \n",
       "18                NaN           0.924870                NaN         GeneD  \n",
       "19                NaN                NaN           0.481117         GeneC  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_storage_SNP_imp=pd.DataFrame(columns=[\"SNP\",\"importance\"])\n",
    "\n",
    "for study in list_of_studies:\n",
    "    print(study,\"study\")\n",
    "    df_studies_rel=df_studies_adj[df_studies_adj[\"study_country_concat\"].isin([study])]\n",
    "\n",
    "    ###prepare dataset\n",
    "    y,X,columns_of_df= subset_study(dm,[study],drug)\n",
    "    X_train, X_test, y_train, y_test=split_dataset_train_test(X, y, test_size_percentage,verbose=0,seednumber=seednumber)\n",
    "\n",
    "    clf = ShortListDecisionTreeClassifier(criterion=\"gini\", splitter='new_best',class_weight=weights, min_samples_leaf=1, feature_genes=feature_genes,\n",
    "                                  short_list=prior_list, max_difference=max_difference_for_heatmap)\n",
    "    \n",
    "    if train_on_full_dataset==1:\n",
    "        clf=fit_model(clf,X_input=X,y_input=y,show_accuracy=1)\n",
    "        predictions_prob,predictions_binary,cm=make_predictions(clf,X_to_test=X,y_to_compare=y)  \n",
    "        TPR,TNR,PPV,NPV,FPR,FNR,FDR,ACC=get_metrics_predictions(cm)\n",
    "        roc_score=get_roc_score(y, predictions_prob)\n",
    "    else:\n",
    "        clf=fit_model(clf,X_input=X_train,y_input=y_train,show_accuracy=1)\n",
    "        predictions_prob,predictions_binary,cm=make_predictions(clf,X_to_test=X_train,y_to_compare=y_test)\n",
    "        TPR,TNR,PPV,NPV,FPR,FNR,FDR,ACC=get_metrics_predictions(cm)\n",
    "        roc_score=get_roc_score(y_test, predictions_prob)\n",
    "\n",
    "    ###get importance scores \n",
    "    df_storage_SNP_imp=get_feature_importance_from_tree(clf,columns_of_df,study,df_storage_SNP_imp,verbose=1,max_difference=max_difference) ##get imporance\n",
    "\n",
    "    ###graphing the tree\n",
    "    plot_tree_per_study(clf, features_names, show_node_types=False, show_id=True,study=study,title_graph=drug_title+\"_tbtree_\"+str(study)) ###plot\n",
    "\n",
    "df_storage_SNP_imp[\"feature_genes\"]=[feature_mapper(f) for f in df_storage_SNP_imp.SNP] ####get genes\n",
    "#df_storage_SNP_imp=get_feature_importance_from_tree(clf,columns_of_df,study,df_storage_SNP_imp,verbose=1,max_difference=max_difference) ##get imporance\n",
    "df_storage_SNP_imp.to_csv(drug_title+\"_feature_importance_comparison.csv\")\n",
    "#plot_tree_per_study(clf, features_names, show_node_types=True, show_id=True,study=study,title_graph=drug_title+\"_tbtree_\"+str(study)) ###plot\n",
    "\n",
    "inputfile=drug_title+\"_feature_importance_comparison.csv\"\n",
    "\n",
    "plot_and_build_heatmap(drug_title,inputfile,remove_importance_label=1,sort_on_snp_loc=1,titlesave=drug_title+\"_heatmap\",subset_list=[\"rpoC\",\"alr\"])\n",
    "t2 = time.time(); print(t2 - t1)\n",
    "\n",
    "###new - renaming\n",
    "df_storage_SNP_imp.feature_genes[df_storage_SNP_imp.feature_genes==\"hsdS.1_bef\"]=\"thyX\" ###rename to align\n",
    "df_storage_SNP_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>SNP</th>\n",
       "      <th>importance_Study1</th>\n",
       "      <th>importance_Study2</th>\n",
       "      <th>importance_Study3</th>\n",
       "      <th>importance_Study4</th>\n",
       "      <th>importance_Study5</th>\n",
       "      <th>feature_genes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_141.0</td>\n",
       "      <td>0.164788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_71.0</td>\n",
       "      <td>0.167534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_1.0</td>\n",
       "      <td>0.086253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneD_641.0</td>\n",
       "      <td>0.236366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_151.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_161.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_191.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004623</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_91.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_121.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.319948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneD_661.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.321623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_171.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_51.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA_61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneD_671.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.924870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeneD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   importance          SNP  importance_Study1  importance_Study2  \\\n",
       "0         NaN  GeneA_141.0           0.164788                NaN   \n",
       "1         NaN   GeneA_71.0           0.167534                NaN   \n",
       "2         NaN    GeneA_1.0           0.086253                NaN   \n",
       "3         NaN  GeneD_641.0           0.236366                NaN   \n",
       "4         NaN  GeneA_151.0                NaN           0.004507   \n",
       "5         NaN  GeneA_161.0                NaN           0.004535   \n",
       "6         NaN  GeneA_191.0                NaN           0.004564   \n",
       "7         NaN   GeneA_21.0                NaN           0.004593   \n",
       "8         NaN   GeneA_41.0                NaN           0.004623   \n",
       "9         NaN   GeneA_91.0                NaN           0.004653   \n",
       "11        NaN  GeneA_121.0                NaN                NaN   \n",
       "12        NaN   GeneA_11.0                NaN                NaN   \n",
       "13        NaN   GeneA_81.0                NaN                NaN   \n",
       "14        NaN  GeneD_661.0                NaN                NaN   \n",
       "15        NaN  GeneA_171.0                NaN                NaN   \n",
       "16        NaN   GeneA_51.0                NaN                NaN   \n",
       "17        NaN   GeneA_61.0                NaN                NaN   \n",
       "18        NaN  GeneD_671.0                NaN                NaN   \n",
       "\n",
       "    importance_Study3  importance_Study4  importance_Study5 feature_genes  \n",
       "0                 NaN                NaN                NaN         GeneA  \n",
       "1                 NaN                NaN                NaN         GeneA  \n",
       "2                 NaN                NaN                NaN         GeneA  \n",
       "3                 NaN                NaN                NaN         GeneD  \n",
       "4                 NaN                NaN                NaN         GeneA  \n",
       "5                 NaN                NaN                NaN         GeneA  \n",
       "6                 NaN                NaN                NaN         GeneA  \n",
       "7                 NaN                NaN                NaN         GeneA  \n",
       "8            0.001592                NaN                NaN         GeneA  \n",
       "9                 NaN                NaN                NaN         GeneA  \n",
       "11           0.319948                NaN                NaN         GeneA  \n",
       "12           0.001583                NaN                NaN         GeneA  \n",
       "13           0.001601                NaN                NaN         GeneA  \n",
       "14           0.321623                NaN                NaN         GeneD  \n",
       "15                NaN           0.004577                NaN         GeneA  \n",
       "16                NaN           0.004604                NaN         GeneA  \n",
       "17                NaN           0.004632                NaN         GeneA  \n",
       "18                NaN           0.924870                NaN         GeneD  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out=df_storage_SNP_imp.groupby(\"feature_genes\").count()\n",
    "\n",
    "df_groupby_snp_level=df_storage_SNP_imp.groupby(\"SNP\").count() ###groupyby at SNP level\n",
    "bool_vector_SNP_more_than_once_across_studies=np.sum(df_groupby_snp_level.iloc[:,:-1]>0,axis=1)>1 ###check SNPs that occur more than once \n",
    "snp_list_more_once=df_groupby_snp_level[bool_vector_SNP_more_than_once_across_studies].index ###get those SNPs\n",
    "gene_list_more_once=list(set([x.split(\"_\")[0] for x in snp_list_more_once])) ###get associated genes\n",
    "\n",
    "bool_vector_gene_more_than_once_across_studies=np.sum(df_out.iloc[:,2:]>0,axis=1)>1 ###decision rule: the gene that contains a SNP to be seen twice across studies \n",
    "bool_vector_gene_more_than_once_in_single_study=np.sum(df_out.iloc[:,2:]>1,axis=1)>0 ###decision rule: the gene that contains a SNP to be seen twice within a study \n",
    "\n",
    "if rule_or_or==1:\n",
    "    bool_vector_total= bool_vector_gene_more_than_once_in_single_study | bool_vector_gene_more_than_once_across_studies\n",
    "else:\n",
    "    bool_vector_total= bool_vector_gene_more_than_once_across_studies\n",
    "\n",
    "dg_out=df_out.loc[bool_vector_total]\n",
    "\n",
    "dg_out=dg_out[~dg_out.index.str.contains('PE')]\n",
    "df_consensus_SNPs=df_storage_SNP_imp[df_storage_SNP_imp[\"feature_genes\"].isin(dg_out.index)] ###subset original dataframe on this index\n",
    "\n",
    "df_consensus_SNPs.to_csv(drug_title+\"_filtered_SNPs.csv\",index=False)\n",
    "df_consensus_SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5060881779936188 roc_score\n",
      "{'regtree_sens': 0.04672897196261682, 'regtree_spec': 1.0, 'regtree_acc': 0.9287211740041929, 'regtree_AUC': 0.5233644859813084, 'TBtree_sens': 0.028037383177570093, 'TBtree_spec': 1.0, 'TBtree_acc': 0.9273235499650594, 'TBtree_AUC': 0.514018691588785, 'sharedsnp_sens': 0.028037383177570093, 'sharedsnp_spec': 0.9841389728096677, 'sharedsnp_acc': 0.9126484975541579, 'sharedsnp_AUC': 0.5060881779936188}\n"
     ]
    }
   ],
   "source": [
    "####detect and write_out shared SNPs\n",
    "#df_consensus_SNPs=df_storage_SNP_imp[df_storage_SNP_imp[\"feature_genes\"].isin(prior_list)].SNP ###old code that only selects known genes\n",
    "shared_SNPs=df_consensus_SNPs.SNP \n",
    "df_shared_snps=pd.DataFrame(shared_SNPs)\n",
    "df_shared_snps.columns=[drug_title]\n",
    "df_shared_snps.to_csv(drug_title+\"_shared_snps\")\n",
    "\n",
    "##Performance of decision making rule that only consensus subset of SNPs\n",
    "y,X,columns_of_df= subset_study(dm,list_of_studies,drug)\n",
    "dm2=dm.loc[:,shared_SNPs]; \n",
    "dm2=dm2.astype(int) \n",
    "dm2[\"hit\"]=np.sum(dm2.iloc[:,:],axis=1) \n",
    "dm2[\"hit\"]=[1 if x > 0 else 0 for x in dm2[\"hit\"]] ####note hits and recode in 01 format \n",
    "cm=confusion_matrix(y, dm2.hit)\n",
    "TPR,TNR,PPV,NPV,FPR,FNR,FDR,ACC=get_metrics_predictions(cm)\n",
    "roc_score=roc_auc_score(y, dm2.hit)\n",
    "print(roc_score,\"roc_score\")\n",
    "perf_dict[\"sharedsnp_sens\"]=TPR;perf_dict[\"sharedsnp_spec\"]=TNR;perf_dict[\"sharedsnp_acc\"]=ACC;perf_dict[\"sharedsnp_AUC\"]=roc_score\n",
    "print(perf_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
